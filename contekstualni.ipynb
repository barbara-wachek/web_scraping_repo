{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPPA8J_xXYBJ",
        "outputId": "3dea3296-b81e-420b-b962-ee4ab17b4c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pydrive\n",
            "  Downloading PyDrive-1.3.1.tar.gz (987 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.4/987.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.12/dist-packages (from pydrive) (2.188.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.12/dist-packages (from pydrive) (6.0.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (0.31.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (0.3.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (2.29.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (4.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (0.6.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (4.9.1)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (1.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.27.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.2->pydrive) (6.2.5)\n",
            "Requirement already satisfied: pyparsing<4,>=3.1 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.2->pydrive) (3.3.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2026.1.4)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pydrive\n",
            "  Building wheel for pydrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydrive: filename=PyDrive-1.3.1-py3-none-any.whl size=27433 sha256=2f95919a14b828354a492420e33a8190b326038faa177fbea3332af82fa3e0bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/10/da/a5b513f5b3916fc391c20ee7b4633e5cf3396d570cdd74970f\n",
            "Successfully built pydrive\n",
            "Installing collected packages: xlsxwriter, pydrive\n",
            "Successfully installed pydrive-1.3.1 xlsxwriter-3.2.9\n"
          ]
        }
      ],
      "source": [
        "!pip install xlsxwriter pydrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% import\n",
        "from __future__ import unicode_literals\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime\n",
        "from time import mktime\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import json\n",
        "import xlsxwriter\n",
        "\n",
        "\n",
        "#%% functions - data conversion\n",
        "\n",
        "def date_change_format(date_string):\n",
        "    \"\"\"\n",
        "    Konwertuje datę z różnych formatów na \"YYYY-MM-DD\"\n",
        "    \"\"\"\n",
        "    try:\n",
        "        date_string = ' '.join(date_string.strip().split())\n",
        "\n",
        "        if re.match(r'\\d{4}-\\d{2}-\\d{2}', date_string):\n",
        "            return date_string[:10]\n",
        "\n",
        "        if 'T' in date_string:\n",
        "            return date_string.split('T')[0]\n",
        "\n",
        "        # Polski słownik miesięcy\n",
        "        lookup_table = {\n",
        "            \"stycznia\": \"01\", \"lutego\": \"02\", \"marca\": \"03\", \"kwietnia\": \"04\",\n",
        "            \"maja\": \"05\", \"czerwca\": \"06\", \"lipca\": \"07\", \"sierpnia\": \"08\",\n",
        "            \"września\": \"09\", \"października\": \"10\", \"listopada\": \"11\", \"grudnia\": \"12\",\n",
        "            \"styczeń\": \"01\", \"luty\": \"02\", \"marzec\": \"03\", \"kwiecień\": \"04\",\n",
        "            \"maj\": \"05\", \"czerwiec\": \"06\", \"lipiec\": \"07\", \"sierpień\": \"08\",\n",
        "            \"wrzesień\": \"09\", \"październik\": \"10\", \"listopad\": \"11\", \"grudzień\": \"12\"\n",
        "        }\n",
        "\n",
        "        for k, v in lookup_table.items():\n",
        "            date_string = date_string.replace(k, v)\n",
        "\n",
        "        if re.match(r'\\d{1,2}\\.\\d{1,2}\\.\\d{4}', date_string):\n",
        "            result = time.strptime(date_string, \"%d.%m.%Y\")\n",
        "        else:\n",
        "            result = time.strptime(date_string, \"%d %m %Y\")\n",
        "\n",
        "        changed_date = datetime.fromtimestamp(mktime(result))\n",
        "        return format(changed_date.date())\n",
        "    except Exception as e:\n",
        "        return \"no date\"\n",
        "\n",
        "\n",
        "#%% functions - link extraction\n",
        "\n",
        "def get_all_article_links():\n",
        "    \"\"\"\n",
        "    Pobiera wszystkie linki do artykułów ze wszystkich kategorii\n",
        "    \"\"\"\n",
        "    base_url = \"https://contekstualni.pl\"\n",
        "\n",
        "    # Kategorie z menu\n",
        "    categories = {\n",
        "        'Literatura': '/literatura/',\n",
        "        'Felietony': '/felietony/',\n",
        "        'Recenzje': '/recenzje/',\n",
        "        'Rozmowy': '/rozmowy/',\n",
        "        'Sztuka': '/sztuka/'\n",
        "    }\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"KROK 1: Pobieranie artykułów z kategorii\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    all_articles = []\n",
        "\n",
        "    for category_name, category_url in categories.items():\n",
        "        print(f\"\\nKategoria: {category_name}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Najpierw pobierz stronę kategorii, żeby sprawdzić paginację\n",
        "        try:\n",
        "            r = requests.get(base_url + category_url, timeout=10)\n",
        "            r.encoding = 'utf-8'\n",
        "\n",
        "            if r.status_code != 200:\n",
        "                print(f\"  ✗ Błąd {r.status_code}\")\n",
        "                continue\n",
        "\n",
        "            soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "            # Pobierz artykuły ze strony kategorii\n",
        "            # Artykuły są w <ul class=\"wp-block-latest-posts__list\">\n",
        "            articles_list = soup.find('ul', class_='wp-block-latest-posts__list')\n",
        "\n",
        "            if articles_list:\n",
        "                article_items = articles_list.find_all('li')\n",
        "\n",
        "                for item in article_items:\n",
        "                    link = item.find('a', class_='wp-block-latest-posts__post-title')\n",
        "                    if link and link.get('href'):\n",
        "                        article_url = link['href']\n",
        "                        article_title = link.get_text(strip=True)\n",
        "\n",
        "                        # Excerpt\n",
        "                        excerpt_div = item.find('div', class_='wp-block-latest-posts__post-excerpt')\n",
        "                        excerpt = excerpt_div.get_text(strip=True) if excerpt_div else \"\"\n",
        "\n",
        "                        all_articles.append({\n",
        "                            'article_url': article_url,\n",
        "                            'article_title': article_title,\n",
        "                            'category': category_name,\n",
        "                            'excerpt': excerpt\n",
        "                        })\n",
        "\n",
        "                print(f\"  ✓ Znaleziono {len(article_items)} artykułów\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Błąd: {e}\")\n",
        "\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    # Dodatkowo: pobierz ze strony głównej (masonry layout)\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Pobieranie ze strony głównej\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        r = requests.get(base_url, timeout=10)\n",
        "        r.encoding = 'utf-8'\n",
        "        soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "        # Artykuły na stronie głównej: <article class=\"post-XXX ...\">\n",
        "        articles = soup.find_all('article', class_=lambda x: x and 'post-' in str(x))\n",
        "\n",
        "        for article in articles:\n",
        "            # Link do artykułu: <h2 class=\"entry-title\"> <a>\n",
        "            title_elem = article.find('h2', class_='entry-title')\n",
        "            if not title_elem:\n",
        "                continue\n",
        "\n",
        "            link = title_elem.find('a')\n",
        "            if not link or not link.get('href'):\n",
        "                continue\n",
        "\n",
        "            article_url = link['href']\n",
        "            article_title = link.get_text(strip=True)\n",
        "\n",
        "            # Kategoria: <div class=\"blog-category-list\"> <a>\n",
        "            category = \"Uncategorized\"\n",
        "            category_div = article.find('div', class_='blog-category-list')\n",
        "            if category_div:\n",
        "                category_link = category_div.find('a')\n",
        "                if category_link:\n",
        "                    category = category_link.get_text(strip=True)\n",
        "\n",
        "            # Excerpt: <div class=\"entry-content\"> <p>\n",
        "            excerpt = \"\"\n",
        "            content_div = article.find('div', class_='entry-content')\n",
        "            if content_div:\n",
        "                p = content_div.find('p')\n",
        "                if p:\n",
        "                    excerpt = p.get_text(strip=True)\n",
        "\n",
        "            # Sprawdź, czy już mamy ten artykuł\n",
        "            if not any(a['article_url'] == article_url for a in all_articles):\n",
        "                all_articles.append({\n",
        "                    'article_url': article_url,\n",
        "                    'article_title': article_title,\n",
        "                    'category': category,\n",
        "                    'excerpt': excerpt\n",
        "                })\n",
        "\n",
        "        print(f\"  ✓ Znaleziono {len(articles)} artykułów\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Błąd: {e}\")\n",
        "\n",
        "    # Usuń duplikaty\n",
        "    unique_articles = []\n",
        "    seen_urls = set()\n",
        "    for article in all_articles:\n",
        "        if article['article_url'] not in seen_urls:\n",
        "            unique_articles.append(article)\n",
        "            seen_urls.add(article['article_url'])\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Łącznie znaleziono: {len(unique_articles)} unikalnych artykułów\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return unique_articles\n",
        "\n",
        "\n",
        "#%% functions - article scraping\n",
        "\n",
        "def scrape_article(article_data):\n",
        "    \"\"\"\n",
        "    Pobiera szczegóły pojedynczego artykułu\n",
        "    \"\"\"\n",
        "    try:\n",
        "        article_url = article_data['article_url']\n",
        "\n",
        "        r = requests.get(article_url, timeout=15)\n",
        "        r.encoding = 'utf-8'\n",
        "\n",
        "        if r.status_code != 200:\n",
        "            errors.append(article_url)\n",
        "            return\n",
        "\n",
        "        soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "        # Kategoria: <div class=\"category-list\"> <a>\n",
        "        category = article_data.get('category', 'no category')\n",
        "        category_div = soup.find('div', class_='category-list')\n",
        "        if category_div:\n",
        "            category_link = category_div.find('a')\n",
        "            if category_link:\n",
        "                category = category_link.get_text(strip=True)\n",
        "\n",
        "        # Tytuł: <h1 class=\"entry-title\">\n",
        "        title = \"no title\"\n",
        "        title_elem = soup.find('h1', class_='entry-title')\n",
        "        if title_elem:\n",
        "            title = title_elem.get_text(strip=True)\n",
        "\n",
        "        # Autor: <span class=\"author vcard\"> <a>\n",
        "        author = \"no author\"\n",
        "        author_span = soup.find('span', class_='author')\n",
        "        if author_span:\n",
        "            author_link = author_span.find('a')\n",
        "            if author_link:\n",
        "                author = author_link.get_text(strip=True)\n",
        "\n",
        "        # Data publikacji: <time class=\"entry-date\">\n",
        "        date_of_publication = \"no date\"\n",
        "        time_elem = soup.find('time', class_='entry-date')\n",
        "        if time_elem and time_elem.get('datetime'):\n",
        "            date_of_publication = date_change_format(time_elem['datetime'])\n",
        "\n",
        "        # Treść artykułu: <div class=\"entry-content\">\n",
        "        text = \"no text\"\n",
        "        content_div = soup.find('div', class_='entry-content')\n",
        "        if content_div:\n",
        "            paragraphs = []\n",
        "\n",
        "            # Zbieramy wszystkie paragrafy\n",
        "            for p in content_div.find_all('p'):\n",
        "                p_text = p.get_text(strip=True)\n",
        "                if p_text:\n",
        "                    paragraphs.append(p_text)\n",
        "\n",
        "            if paragraphs:\n",
        "                text = ' '.join(paragraphs)\n",
        "                text = text.replace('\\n', ' ').replace('\\xa0', ' ')\n",
        "                text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # Linki zewnętrzne\n",
        "        external_links = []\n",
        "        if content_div:\n",
        "            links = content_div.find_all('a', href=True)\n",
        "            for link in links:\n",
        "                href = link['href']\n",
        "                if href.startswith('http') and 'contekstualni.pl' not in href:\n",
        "                    external_links.append(href)\n",
        "\n",
        "        external_links_str = ' | '.join(external_links) if external_links else None\n",
        "\n",
        "        # Zdjęcie wyróżniające: <div class=\"single-featured-image\"> <img>\n",
        "        images = []\n",
        "        featured_div = soup.find('div', class_='single-featured-image')\n",
        "        if featured_div:\n",
        "            img = featured_div.find('img')\n",
        "            if img and img.get('src'):\n",
        "                images.append(img['src'])\n",
        "\n",
        "        # Inne zdjęcia w treści\n",
        "        if content_div:\n",
        "            for img in content_div.find_all('img'):\n",
        "                if img.get('src'):\n",
        "                    img_url = img['src']\n",
        "                    if img_url not in images:\n",
        "                        images.append(img_url)\n",
        "\n",
        "        has_images = len(images) > 0\n",
        "        photos_links = ' | '.join(images) if images else None\n",
        "\n",
        "        # Filmy - sprawdzamy iframe'y\n",
        "        has_videos = False\n",
        "        if content_div:\n",
        "            iframes = content_div.find_all('iframe')\n",
        "            has_videos = len(iframes) > 0\n",
        "\n",
        "        # Tagi: <span class=\"tags-links\"> <a>\n",
        "        tags = []\n",
        "        tags_span = soup.find('span', class_='tags-links')\n",
        "        if tags_span:\n",
        "            tag_links = tags_span.find_all('a')\n",
        "            for tag_link in tag_links:\n",
        "                tag_text = tag_link.get_text(strip=True)\n",
        "                if tag_text:\n",
        "                    tags.append(tag_text)\n",
        "\n",
        "        tags_str = ', '.join(tags) if tags else None\n",
        "\n",
        "        result = {\n",
        "            \"Link\": article_url,\n",
        "            \"Data publikacji\": date_of_publication,\n",
        "            \"Kategoria\": category,\n",
        "            \"Tytuł artykułu\": title,\n",
        "            \"Autor\": author,\n",
        "            \"Tekst artykułu\": text,\n",
        "            \"Tagi\": tags_str,\n",
        "            \"Linki zewnętrzne\": external_links_str,\n",
        "            \"Zdjęcia/Grafika\": has_images,\n",
        "            \"Filmy\": has_videos,\n",
        "            \"Linki do zdjęć\": photos_links\n",
        "        }\n",
        "\n",
        "        all_results.append(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        errors.append(article_data['article_url'])\n",
        "        print(f\"✗ Błąd: {e}\")\n",
        "\n",
        "\n",
        "#%% main execution\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SCRAPER CONTEKSTUALNI.PL\")\n",
        "    print(\"Blog literacko-kulturalny\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    # KROK 1: Pobierz linki do artykułów\n",
        "    article_links = get_all_article_links()\n",
        "\n",
        "    if not article_links:\n",
        "        print(\"Nie znaleziono artykułów!\")\n",
        "        exit(1)\n",
        "\n",
        "    # KROK 2: Scrapuj artykuły\n",
        "    all_results = []\n",
        "    errors = []\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"KROK 2: Scraping artykułów\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    max_workers = 10\n",
        "    print(f\"Używam {max_workers} równoległych wątków\\n\")\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        list(tqdm(executor.map(scrape_article, article_links), total=len(article_links)))\n",
        "\n",
        "    # KROK 3: Zapisz wyniki\n",
        "    timestamp = datetime.today().date()\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"KROK 3: Zapisywanie wyników\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # JSON\n",
        "    json_file = f'contekstualni_{timestamp}.json'\n",
        "    with open(json_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)\n",
        "    print(f\"  ✓ {json_file}\")\n",
        "\n",
        "    # Excel\n",
        "    excel_file = f\"contekstualni_{timestamp}.xlsx\"\n",
        "    df = pd.DataFrame(all_results)\n",
        "    with pd.ExcelWriter(excel_file,\n",
        "                       engine='xlsxwriter',\n",
        "                       engine_kwargs={'options': {'strings_to_urls': False}}) as writer:\n",
        "        df.to_excel(writer, 'Articles', index=False)\n",
        "    print(f\"  ✓ {excel_file}\")\n",
        "\n",
        "    # RAPORT KOŃCOWY\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"RAPORT KOŃCOWY\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Pobranych artykułów: {len(all_results)}\")\n",
        "    print(f\"Błędów: {len(errors)}\")\n",
        "\n",
        "    if errors and len(errors) <= 10:\n",
        "        print(f\"\\nLinki z błędami:\")\n",
        "        for error_link in errors:\n",
        "            print(f\"  - {error_link}\")\n",
        "    elif errors:\n",
        "        print(f\"\\nLinki z błędami (pierwsze 10):\")\n",
        "        for error_link in errors[:10]:\n",
        "            print(f\"  - {error_link}\")\n",
        "        print(f\"  ... i {len(errors) - 10} więcej\")\n",
        "\n",
        "    # Statystyki kategorii\n",
        "    if all_results:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"STATYSTYKI KATEGORII\")\n",
        "        print(\"=\"*60)\n",
        "        category_counts = {}\n",
        "        for result in all_results:\n",
        "            cat = result['Kategoria']\n",
        "            category_counts[cat] = category_counts.get(cat, 0) + 1\n",
        "\n",
        "        for cat, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "            print(f\"  {cat}: {count} artykułów\")\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"GOTOWE!\")\n",
        "    print(\"=\"*60 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0aXKKYrYJOC",
        "outputId": "37bdfe87-1356-47f8-b7b1-b2fef235cfb3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "SCRAPER CONTEKSTUALNI.PL\n",
            "Blog literacko-kulturalny\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "KROK 1: Pobieranie artykułów z kategorii\n",
            "============================================================\n",
            "\n",
            "\n",
            "Kategoria: Literatura\n",
            "----------------------------------------\n",
            "  ✓ Znaleziono 4 artykułów\n",
            "\n",
            "Kategoria: Felietony\n",
            "----------------------------------------\n",
            "  ✓ Znaleziono 0 artykułów\n",
            "\n",
            "Kategoria: Recenzje\n",
            "----------------------------------------\n",
            "  ✓ Znaleziono 8 artykułów\n",
            "\n",
            "Kategoria: Rozmowy\n",
            "----------------------------------------\n",
            "  ✓ Znaleziono 3 artykułów\n",
            "\n",
            "Kategoria: Sztuka\n",
            "----------------------------------------\n",
            "  ✓ Znaleziono 8 artykułów\n",
            "\n",
            "============================================================\n",
            "Pobieranie ze strony głównej\n",
            "============================================================\n",
            "  ✓ Znaleziono 20 artykułów\n",
            "\n",
            "============================================================\n",
            "Łącznie znaleziono: 26 unikalnych artykułów\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "KROK 2: Scraping artykułów\n",
            "============================================================\n",
            "\n",
            "Używam 10 równoległych wątków\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:04<00:00,  5.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "KROK 3: Zapisywanie wyników\n",
            "============================================================\n",
            "  ✓ contekstualni_2026-01-30.json\n",
            "  ✓ contekstualni_2026-01-30.xlsx\n",
            "\n",
            "============================================================\n",
            "RAPORT KOŃCOWY\n",
            "============================================================\n",
            "Pobranych artykułów: 26\n",
            "Błędów: 0\n",
            "\n",
            "============================================================\n",
            "STATYSTYKI KATEGORII\n",
            "============================================================\n",
            "  recenzje: 13 artykułów\n",
            "  sztuka: 6 artykułów\n",
            "  literatura: 4 artykułów\n",
            "  rozmowy: 3 artykułów\n",
            "\n",
            "============================================================\n",
            "GOTOWE!\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/tmp/ipython-input-876800293.py:375: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
            "  df.to_excel(writer, 'Articles', index=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "qnE5jQbNYPtN",
        "outputId": "45ccf91e-449d-4464-84f6-175ac699c805"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Link Data publikacji  \\\n",
              "0                 https://contekstualni.pl/debiut/         no date   \n",
              "1            https://contekstualni.pl/heavy-blood/         no date   \n",
              "2  https://contekstualni.pl/make-room-for-oneself/         no date   \n",
              "3   https://contekstualni.pl/boza-misja-na-wyspie/         no date   \n",
              "4      https://contekstualni.pl/zabawa-w-udawanie/         no date   \n",
              "\n",
              "    Kategoria         Tytuł artykułu Autor  \\\n",
              "0  literatura                 Debiut         \n",
              "1  literatura            Heavy Blood         \n",
              "2    recenzje  Make room for oneself         \n",
              "3    recenzje   Boża misja na wyspie         \n",
              "4    recenzje      Zabawa w udawanie         \n",
              "\n",
              "                                      Tekst artykułu  \\\n",
              "0  Była końcówka listopada. Dzień miał być zimny,...   \n",
              "1  Tak czy inaczej, bywałem również w ciotowatym ...   \n",
              "2  Teatr Łaźnia Nowa, Virginia Woolf,Własny pokój...   \n",
              "3  Rozłożyło mnie, więc leżę w łóżku, faszeruję s...   \n",
              "4  W programie dwudziestego sezonu artystycznego ...   \n",
              "\n",
              "                                                Tagi Linki zewnętrzne  \\\n",
              "0  contekstualni, literatura, opowiadanie, paulin...             None   \n",
              "1  contekstualni, opowiadanie, paulina dąbkowska,...             None   \n",
              "2  contekstualni, dramat, esej, łaźnianowa, pauli...             None   \n",
              "3  BLOG LITERACKI, contekstualni, film, godland, ...             None   \n",
              "4  latający potwór spaghetti, mateusz pakuła, pau...             None   \n",
              "\n",
              "   Zdjęcia/Grafika  Filmy                                     Linki do zdjęć  \n",
              "0             True  False  https://contekstualni.pl/wp-content/uploads/20...  \n",
              "1             True  False  https://contekstualni.pl/wp-content/uploads/20...  \n",
              "2             True  False  https://contekstualni.pl/wp-content/uploads/20...  \n",
              "3             True  False  https://contekstualni.pl/wp-content/uploads/20...  \n",
              "4             True  False  https://contekstualni.pl/wp-content/uploads/20...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-538ca5a1-86a1-40b0-a0d2-5d3572cdb788\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Link</th>\n",
              "      <th>Data publikacji</th>\n",
              "      <th>Kategoria</th>\n",
              "      <th>Tytuł artykułu</th>\n",
              "      <th>Autor</th>\n",
              "      <th>Tekst artykułu</th>\n",
              "      <th>Tagi</th>\n",
              "      <th>Linki zewnętrzne</th>\n",
              "      <th>Zdjęcia/Grafika</th>\n",
              "      <th>Filmy</th>\n",
              "      <th>Linki do zdjęć</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://contekstualni.pl/debiut/</td>\n",
              "      <td>no date</td>\n",
              "      <td>literatura</td>\n",
              "      <td>Debiut</td>\n",
              "      <td></td>\n",
              "      <td>Była końcówka listopada. Dzień miał być zimny,...</td>\n",
              "      <td>contekstualni, literatura, opowiadanie, paulin...</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>https://contekstualni.pl/wp-content/uploads/20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://contekstualni.pl/heavy-blood/</td>\n",
              "      <td>no date</td>\n",
              "      <td>literatura</td>\n",
              "      <td>Heavy Blood</td>\n",
              "      <td></td>\n",
              "      <td>Tak czy inaczej, bywałem również w ciotowatym ...</td>\n",
              "      <td>contekstualni, opowiadanie, paulina dąbkowska,...</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>https://contekstualni.pl/wp-content/uploads/20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://contekstualni.pl/make-room-for-oneself/</td>\n",
              "      <td>no date</td>\n",
              "      <td>recenzje</td>\n",
              "      <td>Make room for oneself</td>\n",
              "      <td></td>\n",
              "      <td>Teatr Łaźnia Nowa, Virginia Woolf,Własny pokój...</td>\n",
              "      <td>contekstualni, dramat, esej, łaźnianowa, pauli...</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>https://contekstualni.pl/wp-content/uploads/20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://contekstualni.pl/boza-misja-na-wyspie/</td>\n",
              "      <td>no date</td>\n",
              "      <td>recenzje</td>\n",
              "      <td>Boża misja na wyspie</td>\n",
              "      <td></td>\n",
              "      <td>Rozłożyło mnie, więc leżę w łóżku, faszeruję s...</td>\n",
              "      <td>BLOG LITERACKI, contekstualni, film, godland, ...</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>https://contekstualni.pl/wp-content/uploads/20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://contekstualni.pl/zabawa-w-udawanie/</td>\n",
              "      <td>no date</td>\n",
              "      <td>recenzje</td>\n",
              "      <td>Zabawa w udawanie</td>\n",
              "      <td></td>\n",
              "      <td>W programie dwudziestego sezonu artystycznego ...</td>\n",
              "      <td>latający potwór spaghetti, mateusz pakuła, pau...</td>\n",
              "      <td>None</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>https://contekstualni.pl/wp-content/uploads/20...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-538ca5a1-86a1-40b0-a0d2-5d3572cdb788')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-538ca5a1-86a1-40b0-a0d2-5d3572cdb788 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-538ca5a1-86a1-40b0-a0d2-5d3572cdb788');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"Link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"https://contekstualni.pl/gaweda-o-uwiklaniach/\",\n          \"https://contekstualni.pl/beksinski-sztuka/\",\n          \"https://contekstualni.pl/debiut/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Data publikacji\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"no date\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kategoria\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"recenzje\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tytu\\u0142 artyku\\u0142u\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"Gaw\\u0119da o uwik\\u0142aniach\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Autor\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tekst artyku\\u0142u\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"Lakierto druga ksi\\u0105\\u017cka prozatorska Jarka Skurzy\\u0144skiego. Nie licz\\u0105c dw\\u00f3ch ksi\\u0105\\u017cek eseistycznychTylko atei\\u015bci zostan\\u0105 zbawieniorazJedena\\u015bcie medytacji nad istnieniem dzie\\u0142a sztuki,debiutowa\\u0142 w prozie w 2020 roku wydan\\u0105 nak\\u0142adem wydawnictwa Ha!art ksi\\u0105\\u017ck\\u0105Zrolowany wrze\\u015bniowy Vogue.Przyznam uczciwie, \\u017ce podchodzi\\u0142am do najnowszej publikacji Skurzy\\u0144skiego z ostro\\u017cno\\u015bci\\u0105. Sam ten pomys\\u0142, aby napisa\\u0107 \\u201egaw\\u0119d\\u0119 przy stole o wsp\\u00f3\\u0142uzale\\u017cnieniu\\u201d wyda\\u0142 mi si\\u0119 ma\\u0142o oryginalny i przypomnia\\u0142 mi ksi\\u0105\\u017ck\\u0119, do kt\\u00f3rej mia\\u0142am nadzieje ju\\u017c nigdy nie wraca\\u0107, mianowicieMatrioszk\\u0119Marty Dzido. By\\u0142a to ksi\\u0105\\u017cka zar\\u00f3wno pretensjonalna, jak i pozbawiona walor\\u00f3w estetycznych, co skutecznie odwiod\\u0142o mnie od czytania tego typu literatury. Za Skurzy\\u0144skim przemawia\\u0142o jednak to, \\u017ce znam jego wcze\\u015bniejsz\\u0105 tw\\u00f3rczo\\u015b\\u0107; cenie szczeg\\u00f3lnie jego pisanie eseistyczne, w\\u0142a\\u015bciwie powinnam na wst\\u0119pie doda\\u0107, \\u017ce autor jest z wykszta\\u0142cenia filozofem. To jednak nie uchroni\\u0142o mnie przed my\\u015bl\\u0105, \\u017ce b\\u0119d\\u0119 musia\\u0142a skierowa\\u0107 w stron\\u0119Lakieruostrze krytyki, ju\\u017c szykowa\\u0142am takow\\u0105a priori, dlaczego uwa\\u017cam to wszystko za jedno wielkie nieporozumienie. I nie ukrywam, \\u017ce ul\\u017cy\\u0142o mi, kiedy okaza\\u0142o si\\u0119, \\u017ce nie b\\u0119d\\u0119 musia\\u0142a tego robi\\u0107, jest to bowiem dobrze napisana opowie\\u015b\\u0107. Ciesz\\u0119 si\\u0119 tym bardziej, \\u017ce w czasach, w kt\\u00f3rych mamy zglobalizowany, a jednocze\\u015bnie zmonopolizowany rynek ksi\\u0105\\u017cki, mam okazje t\\u0119 ksi\\u0105\\u017ck\\u0119 przedstawi\\u0107. * Z zaciekawieniem obserwuje momenty odrywania si\\u0119 autor\\u00f3w od biografizmu. Szczeg\\u00f3lnie na pocz\\u0105tku, bazowanie na w\\u0105tkach w\\u0142asnej historii jest kusz\\u0105ce, ale w dalszej perspektywie mo\\u017ce okaza\\u0107 si\\u0119 pu\\u0142apk\\u0105. Ponadto, uwa\\u017cam, \\u017ce tw\\u00f3rczo\\u015b\\u0107 literacka nie powinna by\\u0107 publicystyczna. Zatem, po osobistym debiucie Skurzy\\u0144ski zdecydowa\\u0142 si\\u0119 na przeskok i postawi\\u0142 na spos\\u00f3b opowiadania historii i budowanie literackich postaci. Ksi\\u0105\\u017ckaLakier,jak ju\\u017c wspomnia\\u0142am, mo\\u017ce sprawia\\u0107 wra\\u017cenie, jakby zosta\\u0142a u\\u0142o\\u017cona ze znanych sk\\u0142adnik\\u00f3w, ale w zmienionych proporcjach. Figur\\u0119 nieobecnego, przemocowego ojca\\u2026 Mamy. Trudne relacje rodzinne? S\\u0105. Ale przecie\\u017c z tego wy\\u0142ania si\\u0119 co\\u015b ciekawego. Gaw\\u0119da rozpoczyna si\\u0119 od narady. Cz\\u0142onkowie rodziny zastanawiaj\\u0105 si\\u0119 co zrobi\\u0107 z choruj\\u0105cym na Alzheimera ojcem. Postawy w rodzinie s\\u0105 bardzo r\\u00f3\\u017cne. Powodem tego nie jest bynajmniej stopie\\u0144 blisko\\u015bci, a uwik\\u0142anie. Mamy do czynienia ze wzorcami wsp\\u00f3\\u0142uzale\\u017cnienia, w kt\\u00f3rych ka\\u017cda osoba z otoczenia porusza si\\u0119 w ramach wyuczonej roli. Jednak to, co Skurzy\\u0144skiemu uda\\u0142o si\\u0119 uchwyci\\u0107, to szczeg\\u00f3lna atmosfera i kr\\u0105\\u017c\\u0105ce po domu poczucie winy, kt\\u00f3re zmusza wszystkich wok\\u00f3\\u0142 do przerzucania si\\u0119 z\\u0142o\\u015bci\\u0105 i podejrzliwo\\u015bci\\u0105. Z czego to wynika, mo\\u017cemy si\\u0119 domy\\u015bla\\u0107: ojciec w przesz\\u0142o\\u015bci nadu\\u017cywa\\u0142 alkoholu i stosowa\\u0142 przemoc wobec bliskich. Zranienia tkwi\\u0105 g\\u0142\\u0119boko. Nie dziwne, \\u017ce rodzina niech\\u0119tnie bierze odpowiedzialno\\u015b\\u0107 za ojca, kt\\u00f3ry nigdy nie wzi\\u0105\\u0142 odpowiedzialno\\u015bci za w\\u0142asne czyny. Tworz\\u0105c posta\\u0107 Stacha, kt\\u00f3rego poznajemy w momencie post\\u0119puj\\u0105cej choroby, a co za tym idzie konsekwentnie utrzymanej \\u201eamnezji\\u201d, autor wycofa\\u0142 go na dalszy plan i trzeba powiedzie\\u0107, \\u017ce to w\\u0142a\\u015bnie ten zabieg pozwoli\\u0142 ujawni\\u0107 panuj\\u0105ce w rodzinie zapl\\u0105tania. Mimo \\u017ce ojciec nie bierze udzia\\u0142u w akcji, jest centraln\\u0105 postaci\\u0105, kt\\u00f3ra determinuje codzienno\\u015b\\u0107 bliskich, narzuca im spos\\u00f3b my\\u015blenia, wp\\u0142ywa na wybory, poci\\u0105ga za sob\\u0105 konkretne decyzje. Nadpsute relacje dostrzegamy r\\u00f3wnie\\u017c mi\\u0119dzy rodze\\u0144stwem, ujawniaj\\u0105 si\\u0119 r\\u00f3wnie\\u017c w stosunku matki do dzieci. Kr\\u0105g powi\\u0119ksza si\\u0119 o synow\\u0105, kt\\u00f3ra wnosi do rodziny w\\u0142asn\\u0105 histori\\u0119. Skurzy\\u0144skiemu uda\\u0142o si\\u0119 zbudowa\\u0107 bohater\\u00f3w, dzi\\u0119ki dobrym dialogom, bo wbrew pozorom, wLakierzeniewiele si\\u0119 zadziewa. Historia utkana jest z my\\u015bli postaci, ich przekona\\u0144 i emocjonalno\\u015bci. Autor wpl\\u00f3t\\u0142 w tkank\\u0119 tekstu w\\u0105tek, o kt\\u00f3rym warto wspomnie\\u0107; Monika, c\\u00f3rka Stacha i Krysi ma najwi\\u0119cej determinacji, aby si\\u0119 wyrwa\\u0107. Bez w\\u0105tpienia, jest to podyktowane tyle\\u017c sytuacj\\u0105 rodzinn\\u0105, co zwi\\u0105zane jest z jej orientacj\\u0105. Skurzy\\u0144ski nie popada jednak w zbytni optymizm. Chorobliwa lojalno\\u015b\\u0107 nie wychodzi nikomu na dobre, a tej nie da si\\u0119 tak \\u0142atwo wyplewi\\u0107. Ka\\u017cdy ma w rodzinie kogo\\u015b, kogo chce ratowa\\u0107. Autor pokaza\\u0142 jak wygl\\u0105da \\u017cycie, kiedy rezygnujemy z siebie na rzecz drugiego cz\\u0142owieka. Czy odpowiedzialno\\u015b\\u0107 za kogo\\u015b jest wa\\u017cniejsza ni\\u017c prawo do my\\u015blenia o sobie? AutorLakierurozwija t\\u0119 kwesti\\u0119 w tek\\u015bcie. Kiedy my pytamy siebie z pozoru niewinnie: a mo\\u017ce to czas leczy rany? Skurzy\\u0144ski podsumowuje dla nas te rozterki jednoznacznie; mechanizm zegara, kt\\u00f3ry piel\\u0119gnowa\\u0142 Stach, nanosz\\u0105c na niego l\\u015bni\\u0105c\\u0105 warstw\\u0119 lakieru jest zahibernowany. A widoczne p\\u0119kni\\u0119cia szybko usuwane przez kolejnych domownik\\u00f3w. Jestem z tej ksi\\u0105\\u017cki zadowolona, przy czym zupe\\u0142nie nie interesuje mnie koniunktura. Zdaj\\u0119 sobie spraw\\u0119, \\u017ceLakiernie zaw\\u0142adnie wyobra\\u017ani\\u0105 t\\u0142um\\u00f3w, jest to jednak ksi\\u0105\\u017cka dojrza\\u0142a, si\\u0119gaj\\u0105ca poza horyzont indywidualnej udr\\u0119ki i osobi\\u015bcie wierz\\u0119, \\u017ce znajdzie swojego czytelnika.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tagi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"BLOG LITERACKI, blog o ksi\\u0105\\u017ckach, contekstualni, jarek skurzy\\u0144ski, jarek skurzynski, lakier, literatura, paulina d\\u0105bkowska, proza, recenzje\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Linki zewn\\u0119trzne\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"https://www.dwutygodnik.com/artykul/1376-powroty-do-piekna.html | http://www.lechmajewski.art.pl/wywiady.php?id=21 | https://kultura.onet.pl/film/wiadomosci/realizacja/cpsffx4?utm_source=www.ecosia.org_viasg_kultura&utm_medium=referal&utm_campaign=leo_automatic&srcc=ucs&utm_v=2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Zdj\\u0119cia/Grafika\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Filmy\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Linki do zdj\\u0119\\u0107\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"https://contekstualni.pl/wp-content/uploads/2023/03/Jarek_Skurzynski-1-3.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}
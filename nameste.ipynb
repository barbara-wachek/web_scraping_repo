{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFjf5QyOXInJ",
        "outputId": "88d7c021-7fec-4e14-d205-3fbfe5664aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pydrive\n",
            "  Downloading PyDrive-1.3.1.tar.gz (987 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/987.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.4/987.4 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.12/dist-packages (from pydrive) (2.187.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.12/dist-packages (from pydrive) (6.0.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (0.2.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (4.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (4.9.1)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (1.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.2->pydrive) (6.2.4)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.2->pydrive) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2025.11.12)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pydrive\n",
            "  Building wheel for pydrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydrive: filename=PyDrive-1.3.1-py3-none-any.whl size=27433 sha256=a092562e7c52225b951b70765b52db06e3bc18e9de7af3a2d37eacbb0f9b571c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/10/da/a5b513f5b3916fc391c20ee7b4633e5cf3396d570cdd74970f\n",
            "Successfully built pydrive\n",
            "Installing collected packages: xlsxwriter, pydrive\n",
            "Successfully installed pydrive-1.3.1 xlsxwriter-3.2.9\n"
          ]
        }
      ],
      "source": [
        "!pip install xlsxwriter pydrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% import\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import re\n",
        "\n",
        "\n",
        "#%% functions\n",
        "\n",
        "def try_sitemap(base_url):\n",
        "    \"\"\"\n",
        "    Próbuje pobrać linki z sitemap.xml\n",
        "    \"\"\"\n",
        "    sitemap_urls = [\n",
        "        f\"{base_url}sitemap-1.xml\",  # Sitemap z postami\n",
        "        f\"{base_url}sitemap.xml\",\n",
        "        f\"{base_url}sitemap_index.xml\",\n",
        "        f\"{base_url}wp-sitemap.xml\",\n",
        "        f\"{base_url}sitemap-posts.xml\"\n",
        "    ]\n",
        "\n",
        "    for sitemap_url in sitemap_urls:\n",
        "        try:\n",
        "            print(f\"  Próbuję: {sitemap_url}\")\n",
        "            r = requests.get(sitemap_url, timeout=10)\n",
        "            if r.status_code == 200:\n",
        "                soup = BeautifulSoup(r.text, 'xml')\n",
        "                links = [loc.text.strip() for loc in soup.find_all('loc')]\n",
        "                if links:\n",
        "                    print(f\"  ✓ Znaleziono sitemap: {sitemap_url}\")\n",
        "                    print(f\"  ✓ Linków w sitemap: {len(links)}\")\n",
        "                    return links\n",
        "        except Exception as e:\n",
        "            print(f\"    Błąd: {e}\")\n",
        "            continue\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_article_links_from_page(page_url):\n",
        "    \"\"\"\n",
        "    Pobiera linki do artykułów z pojedynczej strony\n",
        "    \"\"\"\n",
        "    try:\n",
        "        r = requests.get(page_url)\n",
        "        r.encoding = 'utf-8'\n",
        "        soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "        article_links = []\n",
        "        for article in soup.find_all('article'):\n",
        "            title = article.find(['h1', 'h2', 'h3'], class_=lambda x: x and 'entry-title' in str(x).lower())\n",
        "            if title:\n",
        "                link = title.find('a', href=True)\n",
        "                if link:\n",
        "                    href = link['href']\n",
        "                    if 'nameste.litglog.org' in href or href.startswith('/'):\n",
        "                        if href.startswith('/'):\n",
        "                            href = 'https://nameste.litglog.org' + href\n",
        "                        article_links.append(href)\n",
        "\n",
        "        return article_links\n",
        "    except Exception as e:\n",
        "        print(f\"Błąd dla {page_url}: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def get_all_pages(blog_url):\n",
        "    \"\"\"\n",
        "    Znajduje wszystkie strony paginacji\n",
        "    \"\"\"\n",
        "    pages = [blog_url]\n",
        "    try:\n",
        "        page_num = 2\n",
        "        while True:\n",
        "            # WordPress paginacja: /page/2/, /page/3/\n",
        "            next_page = blog_url.rstrip('/') + f'/page/{page_num}/'\n",
        "            r = requests.get(next_page)\n",
        "\n",
        "            if r.status_code == 200 and r.url != blog_url:\n",
        "                pages.append(next_page)\n",
        "                print(f\"  Znaleziono stronę {page_num}\")\n",
        "                page_num += 1\n",
        "                time.sleep(0.5)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        return pages\n",
        "    except Exception as e:\n",
        "        print(f\"Błąd paginacji: {e}\")\n",
        "        return pages\n",
        "\n",
        "\n",
        "def get_all_article_links(blog_url):\n",
        "    \"\"\"\n",
        "    Główna funkcja - pobiera wszystkie linki\n",
        "    \"\"\"\n",
        "    # Najpierw próbuj sitemap\n",
        "    print(\"Krok 1: Próba pobrania sitemap...\")\n",
        "    sitemap_links = try_sitemap(blog_url)\n",
        "\n",
        "    if sitemap_links:\n",
        "        print(f\"Znaleziono {len(sitemap_links)} linków w sitemap\")\n",
        "        return sitemap_links, []\n",
        "\n",
        "    print(\"Brak sitemap, używam paginacji...\")\n",
        "\n",
        "    # Paginacja\n",
        "    print(\"\\nKrok 2: Szukanie stron...\")\n",
        "    all_pages = get_all_pages(blog_url)\n",
        "    print(f\"Znaleziono {len(all_pages)} stron\")\n",
        "\n",
        "    all_article_links = []\n",
        "    errors = []\n",
        "\n",
        "    print(\"\\nKrok 3: Pobieranie artykułów...\")\n",
        "    for page_url in tqdm(all_pages, desc=\"Przetwarzanie\"):\n",
        "        try:\n",
        "            time.sleep(0.5)\n",
        "            article_links = get_article_links_from_page(page_url)\n",
        "            all_article_links.extend(article_links)\n",
        "        except Exception as e:\n",
        "            errors.append(page_url)\n",
        "\n",
        "    # Usuń duplikaty\n",
        "    all_article_links = list(set(all_article_links))\n",
        "\n",
        "    return all_article_links, errors\n",
        "\n",
        "\n",
        "def filter_article_links(all_links):\n",
        "    \"\"\"\n",
        "    Filtruje linki - zostawia tylko artykuły\n",
        "    \"\"\"\n",
        "    article_links = []\n",
        "    excluded = {'category': 0, 'tag': 0, 'page': 0, 'author': 0, 'other': 0}\n",
        "\n",
        "    for link in all_links:\n",
        "        # Usuń fragmenty (#)\n",
        "        link = link.split('#')[0].rstrip('/')\n",
        "\n",
        "        if not link:\n",
        "            continue\n",
        "\n",
        "        # Wykluczamy\n",
        "        if '/category/' in link or '/tag/' in link:\n",
        "            excluded['category'] += 1\n",
        "            continue\n",
        "        if '/author/' in link:\n",
        "            excluded['author'] += 1\n",
        "            continue\n",
        "        if '/page/' in link:\n",
        "            excluded['page'] += 1\n",
        "            continue\n",
        "\n",
        "        # Główna strona\n",
        "        if link == 'https://nameste.litglog.org' or link.endswith('.org/'):\n",
        "            excluded['other'] += 1\n",
        "            continue\n",
        "\n",
        "        article_links.append(link)\n",
        "\n",
        "    # Usuń duplikaty\n",
        "    article_links = list(set(article_links))\n",
        "\n",
        "    print(f\"\\nStatystyki filtrowania:\")\n",
        "    print(f\"  Kategorie/tagi: {excluded['category'] + excluded['tag']}\")\n",
        "    print(f\"  Autorzy: {excluded['author']}\")\n",
        "    print(f\"  Paginacja: {excluded['page']}\")\n",
        "    print(f\"  Inne: {excluded['other']}\")\n",
        "    print(f\"  ✅ ZAAKCEPTOWANO: {len(article_links)}\")\n",
        "\n",
        "    return article_links\n",
        "\n",
        "\n",
        "#%% main execution\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    blog_url = \"https://nameste.litglog.org/\"\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"Pobieranie linków z nameste.litglog.org\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    # Pobierz wszystkie linki\n",
        "    all_links, errors = get_all_article_links(blog_url)\n",
        "\n",
        "    print(f\"\\nZnaleziono {len(all_links)} linków\")\n",
        "\n",
        "    # Filtruj\n",
        "    article_links = filter_article_links(all_links)\n",
        "\n",
        "    if not article_links:\n",
        "        print(\"\\n⚠️  Nie znaleziono artykułów!\")\n",
        "        exit(1)\n",
        "\n",
        "    # Pokaż przykłady\n",
        "    if article_links:\n",
        "        print(\"\\nPrzykładowe linki (pierwsze 10):\")\n",
        "        for i, link in enumerate(sorted(article_links)[:10], 1):\n",
        "            print(f\"  {i}. {link}\")\n",
        "\n",
        "        if len(article_links) > 10:\n",
        "            print(f\"  ... i {len(article_links) - 10} więcej\")\n",
        "\n",
        "    # Sortuj\n",
        "    article_links.sort()\n",
        "\n",
        "    # Zapisz\n",
        "    with open('nameste_linki.txt', 'w', encoding='utf-8') as f:\n",
        "        for link in article_links:\n",
        "            f.write(link + '\\n')\n",
        "\n",
        "    output_data = {\n",
        "        'source': blog_url,\n",
        "        'total_links': len(article_links),\n",
        "        'links': article_links,\n",
        "        'errors': errors\n",
        "    }\n",
        "\n",
        "    with open('nameste_linki.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # Raport\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RAPORT\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Znaleziono artykułów: {len(article_links)}\")\n",
        "    print(f\"Błędów: {len(errors)}\")\n",
        "    print(f\"\\nZapisano do:\")\n",
        "    print(f\"  - nameste_linki.txt\")\n",
        "    print(f\"  - nameste_linki.json\")\n",
        "    print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8fxVGfjX9Hn",
        "outputId": "a8c4b9c5-4470-4ca5-b4ba-d53cfd36ae90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Pobieranie linków z nameste.litglog.org\n",
            "============================================================\n",
            "\n",
            "Krok 1: Próba pobrania sitemap...\n",
            "  Próbuję: https://nameste.litglog.org/sitemap-1.xml\n",
            "  ✓ Znaleziono sitemap: https://nameste.litglog.org/sitemap-1.xml\n",
            "  ✓ Linków w sitemap: 696\n",
            "Znaleziono 696 linków w sitemap\n",
            "\n",
            "Znaleziono 696 linków\n",
            "\n",
            "Statystyki filtrowania:\n",
            "  Kategorie/tagi: 0\n",
            "  Autorzy: 0\n",
            "  Paginacja: 0\n",
            "  Inne: 1\n",
            "  ✅ ZAAKCEPTOWANO: 695\n",
            "\n",
            "Przykładowe linki (pierwsze 10):\n",
            "  1. https://nameste.litglog.org/2008/08/rebetiko\n",
            "  2. https://nameste.litglog.org/2008/08/saudade\n",
            "  3. https://nameste.litglog.org/2009/01/lekcja-limeryczna\n",
            "  4. https://nameste.litglog.org/2009/03/chazarski-smutek\n",
            "  5. https://nameste.litglog.org/2009/04/konsekwencja-leksykalna\n",
            "  6. https://nameste.litglog.org/2009/06/babel\n",
            "  7. https://nameste.litglog.org/2009/06/tlingit\n",
            "  8. https://nameste.litglog.org/2009/07/drugie-wyrojenie-budyniow\n",
            "  9. https://nameste.litglog.org/2009/10/c-j-cz-cz\n",
            "  10. https://nameste.litglog.org/2009/10/p\n",
            "  ... i 685 więcej\n",
            "\n",
            "============================================================\n",
            "RAPORT\n",
            "============================================================\n",
            "Znaleziono artykułów: 695\n",
            "Błędów: 0\n",
            "\n",
            "Zapisano do:\n",
            "  - nameste_linki.txt\n",
            "  - nameste_linki.json\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% import\n",
        "from __future__ import unicode_literals\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime\n",
        "from time import mktime\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import json\n",
        "import xlsxwriter\n",
        "\n",
        "\n",
        "#%% functions\n",
        "\n",
        "def date_change_format(date_string):\n",
        "    \"\"\"\n",
        "    Konwertuje datę z różnych formatów na \"YYYY-MM-DD\"\n",
        "    \"\"\"\n",
        "    try:\n",
        "        date_string = ' '.join(date_string.strip().split())\n",
        "\n",
        "        if re.match(r'\\d{4}-\\d{2}-\\d{2}', date_string):\n",
        "            return date_string[:10]\n",
        "\n",
        "        if 'T' in date_string:\n",
        "            return date_string.split('T')[0]\n",
        "\n",
        "        lookup_table = {\n",
        "            \"stycznia\": \"01\", \"lutego\": \"02\", \"marca\": \"03\", \"kwietnia\": \"04\",\n",
        "            \"maja\": \"05\", \"czerwca\": \"06\", \"lipca\": \"07\", \"sierpnia\": \"08\",\n",
        "            \"września\": \"09\", \"października\": \"10\", \"listopada\": \"11\", \"grudnia\": \"12\",\n",
        "            \"styczeń\": \"01\", \"luty\": \"02\", \"marzec\": \"03\", \"kwiecień\": \"04\",\n",
        "            \"maj\": \"05\", \"czerwiec\": \"06\", \"lipiec\": \"07\", \"sierpień\": \"08\",\n",
        "            \"wrzesień\": \"09\", \"październik\": \"10\", \"listopad\": \"11\", \"grudzień\": \"12\"\n",
        "        }\n",
        "\n",
        "        for k, v in lookup_table.items():\n",
        "            date_string = date_string.replace(k, v)\n",
        "\n",
        "        if re.match(r'\\d{1,2}\\.\\d{1,2}\\.\\d{4}', date_string):\n",
        "            result = time.strptime(date_string, \"%d.%m.%Y\")\n",
        "        else:\n",
        "            result = time.strptime(date_string, \"%d %m %Y\")\n",
        "\n",
        "        changed_date = datetime.fromtimestamp(mktime(result))\n",
        "        return format(changed_date.date())\n",
        "    except Exception as e:\n",
        "        return \"no date\"\n",
        "\n",
        "\n",
        "def dictionary_of_article(article_link):\n",
        "    \"\"\"\n",
        "    Pobiera szczegóły artykułu z nameste.litglog.org (WordPress)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        r = requests.get(article_link)\n",
        "        r.encoding = 'utf-8'\n",
        "        html_text = r.text\n",
        "\n",
        "        while '429 Too Many Requests' in html_text:\n",
        "            time.sleep(5)\n",
        "            r = requests.get(article_link)\n",
        "            r.encoding = 'utf-8'\n",
        "            html_text = r.text\n",
        "\n",
        "        soup = BeautifulSoup(html_text, 'lxml')\n",
        "\n",
        "        # Data publikacji\n",
        "        try:\n",
        "            # Opcja 1: span.date.updated\n",
        "            date_element = soup.find('span', class_='date')\n",
        "            if not date_element:\n",
        "                date_element = soup.find('span', class_='updated')\n",
        "\n",
        "            # Opcja 2: .entry-date\n",
        "            if not date_element:\n",
        "                date_element = soup.find(class_='entry-date')\n",
        "\n",
        "            # Opcja 3: <time>\n",
        "            if not date_element:\n",
        "                date_element = soup.find('time')\n",
        "\n",
        "            # Opcja 4: Meta tag\n",
        "            if not date_element:\n",
        "                meta_date = soup.find('meta', property='article:published_time')\n",
        "                if meta_date:\n",
        "                    date_element = type('obj', (object,), {\n",
        "                        'get_text': lambda: meta_date.get('content', ''),\n",
        "                        'get': lambda x: meta_date.get('content', '')\n",
        "                    })()\n",
        "\n",
        "            if date_element:\n",
        "                date_text = date_element.get('datetime') or date_element.get('content') or date_element.get_text(strip=True)\n",
        "                date_of_publication = date_change_format(date_text)\n",
        "            else:\n",
        "                date_of_publication = \"no date\"\n",
        "        except Exception as e:\n",
        "            date_of_publication = \"no date\"\n",
        "\n",
        "        # Tytuł\n",
        "        try:\n",
        "            title_element = soup.find('h1', class_=lambda x: x and 'entry-title' in str(x).lower())\n",
        "            if not title_element:\n",
        "                title_element = soup.find('h1')\n",
        "\n",
        "            title = title_element.get_text(strip=True) if title_element else \"no title\"\n",
        "        except:\n",
        "            title = \"no title\"\n",
        "\n",
        "        # Autor\n",
        "        try:\n",
        "            author_element = soup.find('a', rel='author')\n",
        "            if not author_element:\n",
        "                author_element = soup.find(['span', 'div'], class_=lambda x: x and 'author' in str(x).lower())\n",
        "\n",
        "            if author_element:\n",
        "                author = author_element.get_text(strip=True)\n",
        "                author = re.sub(r'^(Autor|By|Opublikował):\\s*', '', author, flags=re.IGNORECASE)\n",
        "            else:\n",
        "                author = \"no author\"\n",
        "        except:\n",
        "            author = \"no author\"\n",
        "\n",
        "        # Treść artykułu\n",
        "        try:\n",
        "            # Opcja 1: .entry-content\n",
        "            article_body = soup.find('div', class_=lambda x: x and 'entry-content' in str(x).lower())\n",
        "\n",
        "            # Opcja 2: .post-content\n",
        "            if not article_body:\n",
        "                article_body = soup.find('div', class_=lambda x: x and 'post-content' in str(x).lower())\n",
        "\n",
        "            # Opcja 3: <article> - zbierz wszystkie <p> w środku\n",
        "            if not article_body:\n",
        "                article_elem = soup.find('article')\n",
        "                if article_elem:\n",
        "                    # Zbierz wszystkie paragrafy\n",
        "                    paragraphs = article_elem.find_all('p')\n",
        "                    if paragraphs:\n",
        "                        # Stwórz sztuczny kontener\n",
        "                        article_body = BeautifulSoup('<div></div>', 'lxml').div\n",
        "                        for p in paragraphs:\n",
        "                            article_body.append(p)\n",
        "\n",
        "            # Opcja 4: Wszystkie <p> na stronie (ostateczność)\n",
        "            if not article_body:\n",
        "                paragraphs = soup.find_all('p')\n",
        "                if paragraphs:\n",
        "                    article_body = BeautifulSoup('<div></div>', 'lxml').div\n",
        "                    for p in paragraphs:\n",
        "                        article_body.append(p)\n",
        "\n",
        "            if article_body:\n",
        "                text = article_body.get_text(strip=True).replace('\\n', ' ').replace('\\xa0', ' ')\n",
        "                # Usuń bardzo długie spacje\n",
        "                text = re.sub(r'\\s+', ' ', text)\n",
        "            else:\n",
        "                text = \"no text\"\n",
        "        except Exception as e:\n",
        "            print(f\"Błąd pobierania tekstu dla {article_link}: {e}\")\n",
        "            text = \"no text\"\n",
        "\n",
        "        # Kategoria\n",
        "        try:\n",
        "            # Opcja 1: span.categories z linkami\n",
        "            categories_span = soup.find('span', class_='categories')\n",
        "            if categories_span:\n",
        "                category_links = categories_span.find_all('a', rel='category tag')\n",
        "                if category_links:\n",
        "                    categories = [cat.get_text(strip=True) for cat in category_links]\n",
        "                    category = ' | '.join(categories)\n",
        "                else:\n",
        "                    category = \"no category\"\n",
        "            else:\n",
        "                # Opcja 2: Standardowe WordPress\n",
        "                category_links = soup.find_all('a', rel='category tag')\n",
        "                if not category_links:\n",
        "                    category_links = soup.find_all('a', rel='category')\n",
        "\n",
        "                if category_links:\n",
        "                    categories = [cat.get_text(strip=True) for cat in category_links]\n",
        "                    category = ' | '.join(categories)\n",
        "                else:\n",
        "                    category = \"no category\"\n",
        "        except:\n",
        "            category = \"no category\"\n",
        "\n",
        "        # Tagi\n",
        "        try:\n",
        "            tag_links = soup.find_all('a', rel='tag')\n",
        "            if tag_links:\n",
        "                tags = [tag.get_text(strip=True) for tag in tag_links]\n",
        "                tags_str = ' | '.join(tags)\n",
        "            else:\n",
        "                tags_str = None\n",
        "        except:\n",
        "            tags_str = None\n",
        "\n",
        "        # Linki zewnętrzne\n",
        "        try:\n",
        "            if article_body:\n",
        "                links = [a['href'] for a in article_body.find_all('a', href=True)]\n",
        "                external_links = [link for link in links if not re.search(r'nameste\\.litglog\\.org', link)]\n",
        "                external_links = ' | '.join(external_links) if external_links else None\n",
        "            else:\n",
        "                external_links = None\n",
        "        except (AttributeError, KeyError, IndexError):\n",
        "            external_links = None\n",
        "\n",
        "        # Zdjęcia\n",
        "        try:\n",
        "            images = []\n",
        "\n",
        "            # Thumbnail\n",
        "            thumbnail_div = soup.find('div', class_=lambda x: x and 'post-thumbnail' in str(x).lower())\n",
        "            if thumbnail_div:\n",
        "                thumb_img = thumbnail_div.find('img', src=True)\n",
        "                if thumb_img:\n",
        "                    images.append(thumb_img['src'])\n",
        "\n",
        "            # Featured image\n",
        "            if not images:\n",
        "                featured_img = soup.find('img', class_=lambda x: x and 'wp-post-image' in str(x).lower())\n",
        "                if featured_img and featured_img.get('src'):\n",
        "                    images.append(featured_img['src'])\n",
        "\n",
        "            # Zdjęcia w treści\n",
        "            if article_body:\n",
        "                content_images = [img['src'] for img in article_body.find_all('img', src=True) if img.get('src')]\n",
        "                for img_src in content_images:\n",
        "                    if img_src not in images:\n",
        "                        images.append(img_src)\n",
        "\n",
        "            has_images = len(images) > 0\n",
        "            photos_links = ' | '.join(images) if images else None\n",
        "        except (AttributeError, KeyError, IndexError):\n",
        "            has_images = False\n",
        "            photos_links = None\n",
        "\n",
        "        # Filmy\n",
        "        try:\n",
        "            if article_body:\n",
        "                iframes = [iframe['src'] for iframe in article_body.find_all('iframe', src=True)]\n",
        "                has_videos = len(iframes) > 0\n",
        "            else:\n",
        "                has_videos = False\n",
        "        except:\n",
        "            has_videos = False\n",
        "\n",
        "        dictionary_of_article = {\n",
        "            \"Link\": article_link,\n",
        "            \"Data publikacji\": date_of_publication,\n",
        "            \"Tytuł artykułu\": title.replace('\\xa0', ' '),\n",
        "            \"Tekst artykułu\": text,\n",
        "            \"Autor\": author,\n",
        "            \"Kategoria\": category,\n",
        "            \"Tagi\": tags_str,\n",
        "            \"Linki zewnętrzne\": external_links,\n",
        "            \"Zdjęcia/Grafika\": has_images,\n",
        "            \"Filmy\": has_videos,\n",
        "            \"Linki do zdjęć\": photos_links\n",
        "        }\n",
        "\n",
        "        all_results.append(dictionary_of_article)\n",
        "\n",
        "    except AttributeError as e:\n",
        "        errors.append(article_link)\n",
        "        print(f\"Błąd dla {article_link}: {e}\")\n",
        "    except Exception as e:\n",
        "        errors.append(article_link)\n",
        "        print(f\"Nieoczekiwany błąd dla {article_link}: {e}\")\n",
        "\n",
        "\n",
        "#%% main execution\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Wczytaj linki\n",
        "    try:\n",
        "        with open('nameste_linki.txt', 'r', encoding='utf-8') as f:\n",
        "            article_links = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "        print(f\"Wczytano {len(article_links)} linków z pliku\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Nie znaleziono pliku nameste_linki.txt\")\n",
        "        print(\"Użyj najpierw get_nameste_links.py!\")\n",
        "        article_links = []\n",
        "\n",
        "    if not article_links:\n",
        "        print(\"Brak linków do przetworzenia!\")\n",
        "        exit(1)\n",
        "\n",
        "    all_results = []\n",
        "    errors = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Rozpoczynam scraping artykułów z nameste.litglog.org\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    # Scraping\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        list(tqdm(executor.map(dictionary_of_article, article_links), total=len(article_links)))\n",
        "\n",
        "    # Zapisywanie\n",
        "    timestamp = datetime.today().date()\n",
        "\n",
        "    # JSON\n",
        "    with open(f'nameste_{timestamp}.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)\n",
        "\n",
        "    # Excel\n",
        "    df = pd.DataFrame(all_results)\n",
        "    with pd.ExcelWriter(f\"nameste_{timestamp}.xlsx\",\n",
        "                       engine='xlsxwriter',\n",
        "                       engine_kwargs={'options': {'strings_to_urls': False}}) as writer:\n",
        "        df.to_excel(writer, 'Posts', index=False)\n",
        "\n",
        "    # Raport\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Scraping zakończony!\")\n",
        "    print(f\"Przetworzono artykułów: {len(all_results)}\")\n",
        "    print(f\"Błędów: {len(errors)}\")\n",
        "    if errors:\n",
        "        print(f\"\\nLinki z błędami (pierwsze 10):\")\n",
        "        for error_link in errors[:10]:\n",
        "            print(f\"  - {error_link}\")\n",
        "        if len(errors) > 10:\n",
        "            print(f\"  ... i {len(errors) - 10} więcej\")\n",
        "    print(f\"\\nPliki wyjściowe:\")\n",
        "    print(f\"  - nameste_{timestamp}.json\")\n",
        "    print(f\"  - nameste_{timestamp}.xlsx\")\n",
        "    print(f\"{'='*60}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRknMNzQYep9",
        "outputId": "354911d2-eff4-487e-8ca5-354cd36507c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wczytano 695 linków z pliku\n",
            "\n",
            "============================================================\n",
            "Rozpoczynam scraping artykułów z nameste.litglog.org\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 695/695 [02:55<00:00,  3.97it/s]\n",
            "/tmp/ipython-input-4089240125.py:318: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
            "  df.to_excel(writer, 'Posts', index=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Scraping zakończony!\n",
            "Przetworzono artykułów: 695\n",
            "Błędów: 0\n",
            "\n",
            "Pliki wyjściowe:\n",
            "  - nameste_2026-01-12.json\n",
            "  - nameste_2026-01-12.xlsx\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "7sSLVUgXZvTu",
        "outputId": "b2f173e1-5c8d-43d5-9a8b-291dc2b0d7cf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Link Data publikacji  \\\n",
              "0        https://nameste.litglog.org/2008/08/saudade      2008-08-10   \n",
              "1       https://nameste.litglog.org/2008/08/rebetiko      2008-08-30   \n",
              "2  https://nameste.litglog.org/2009/03/chazarski-...      2009-03-15   \n",
              "3  https://nameste.litglog.org/2009/01/lekcja-lim...      2009-01-23   \n",
              "4  https://nameste.litglog.org/2009/04/konsekwenc...      2009-04-09   \n",
              "\n",
              "            Tytuł artykułu                                     Tekst artykułu  \\\n",
              "0                  saudade  rebetiko ›2008-08-10inz-archiwum|1 commentSaud...   \n",
              "1                 rebetiko  ‹ saudade•lekcja limeryczna ›2008-08-30inz-arc...   \n",
              "2         chazarski smutek  ‹ lekcja limeryczna•konsekwencja leksykalna ›2...   \n",
              "3        lekcja limeryczna  ‹ rebetiko•chazarski smutek ›2009-01-23inz-arc...   \n",
              "4  konsekwencja leksykalna  ‹ chazarski smutek•Babel ›2009-04-09inz-archiw...   \n",
              "\n",
              "     Autor    Kategoria  Tagi  \\\n",
              "0   andsol  no category  None   \n",
              "1  nameste  no category  None   \n",
              "2  nameste  no category  None   \n",
              "3  nameste  no category  None   \n",
              "4  nameste  no category  None   \n",
              "\n",
              "                                    Linki zewnętrzne  Zdjęcia/Grafika  Filmy  \\\n",
              "0  https://andsol.wordpress.com/ | https://andsol...            False  False   \n",
              "1  http://worldmusic.nationalgeographic.com/world...            False  False   \n",
              "2        http://wordpress.org/ | https://likebtn.com            False  False   \n",
              "3  http://pocztowkizlaputy.blogspot.com/2009/01/k...            False  False   \n",
              "4        http://wordpress.org/ | https://likebtn.com            False  False   \n",
              "\n",
              "  Linki do zdjęć  \n",
              "0           None  \n",
              "1           None  \n",
              "2           None  \n",
              "3           None  \n",
              "4           None  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7de8228-9f18-499a-9c43-b8d1708b2412\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Link</th>\n",
              "      <th>Data publikacji</th>\n",
              "      <th>Tytuł artykułu</th>\n",
              "      <th>Tekst artykułu</th>\n",
              "      <th>Autor</th>\n",
              "      <th>Kategoria</th>\n",
              "      <th>Tagi</th>\n",
              "      <th>Linki zewnętrzne</th>\n",
              "      <th>Zdjęcia/Grafika</th>\n",
              "      <th>Filmy</th>\n",
              "      <th>Linki do zdjęć</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://nameste.litglog.org/2008/08/saudade</td>\n",
              "      <td>2008-08-10</td>\n",
              "      <td>saudade</td>\n",
              "      <td>rebetiko ›2008-08-10inz-archiwum|1 commentSaud...</td>\n",
              "      <td>andsol</td>\n",
              "      <td>no category</td>\n",
              "      <td>None</td>\n",
              "      <td>https://andsol.wordpress.com/ | https://andsol...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://nameste.litglog.org/2008/08/rebetiko</td>\n",
              "      <td>2008-08-30</td>\n",
              "      <td>rebetiko</td>\n",
              "      <td>‹ saudade•lekcja limeryczna ›2008-08-30inz-arc...</td>\n",
              "      <td>nameste</td>\n",
              "      <td>no category</td>\n",
              "      <td>None</td>\n",
              "      <td>http://worldmusic.nationalgeographic.com/world...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://nameste.litglog.org/2009/03/chazarski-...</td>\n",
              "      <td>2009-03-15</td>\n",
              "      <td>chazarski smutek</td>\n",
              "      <td>‹ lekcja limeryczna•konsekwencja leksykalna ›2...</td>\n",
              "      <td>nameste</td>\n",
              "      <td>no category</td>\n",
              "      <td>None</td>\n",
              "      <td>http://wordpress.org/ | https://likebtn.com</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://nameste.litglog.org/2009/01/lekcja-lim...</td>\n",
              "      <td>2009-01-23</td>\n",
              "      <td>lekcja limeryczna</td>\n",
              "      <td>‹ rebetiko•chazarski smutek ›2009-01-23inz-arc...</td>\n",
              "      <td>nameste</td>\n",
              "      <td>no category</td>\n",
              "      <td>None</td>\n",
              "      <td>http://pocztowkizlaputy.blogspot.com/2009/01/k...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://nameste.litglog.org/2009/04/konsekwenc...</td>\n",
              "      <td>2009-04-09</td>\n",
              "      <td>konsekwencja leksykalna</td>\n",
              "      <td>‹ chazarski smutek•Babel ›2009-04-09inz-archiw...</td>\n",
              "      <td>nameste</td>\n",
              "      <td>no category</td>\n",
              "      <td>None</td>\n",
              "      <td>http://wordpress.org/ | https://likebtn.com</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7de8228-9f18-499a-9c43-b8d1708b2412')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b7de8228-9f18-499a-9c43-b8d1708b2412 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b7de8228-9f18-499a-9c43-b8d1708b2412');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b13e4d05-5f45-4add-a080-9720b63f64fa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b13e4d05-5f45-4add-a080-9720b63f64fa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b13e4d05-5f45-4add-a080-9720b63f64fa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}
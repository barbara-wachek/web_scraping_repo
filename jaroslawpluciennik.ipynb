{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter pydrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvqA5u33dkhq",
        "outputId": "7dc47760-16b7-431c-9df9-86f13b403156"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pydrive\n",
            "  Downloading PyDrive-1.3.1.tar.gz (987 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.4/987.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.12/dist-packages (from pydrive) (2.187.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.12/dist-packages (from pydrive) (6.0.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (0.2.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.2->pydrive) (4.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (4.9.1)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from oauth2client>=4.0.0->pydrive) (1.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.2->pydrive) (6.2.4)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client>=1.2->pydrive) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2025.11.12)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pydrive\n",
            "  Building wheel for pydrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydrive: filename=PyDrive-1.3.1-py3-none-any.whl size=27433 sha256=8f5c20aa3ade6cd5c918c13556c2bc64374dbb9c585f2741c261fbc412777042\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/10/da/a5b513f5b3916fc391c20ee7b4633e5cf3396d570cdd74970f\n",
            "Successfully built pydrive\n",
            "Installing collected packages: xlsxwriter, pydrive\n",
            "Successfully installed pydrive-1.3.1 xlsxwriter-3.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYGBFElMdiR2",
        "outputId": "98143ffe-2966-4bee-b5d6-fffad662180e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Pobieranie wszystkich linków z jaroslawpluciennik.com/blog/\n",
            "============================================================\n",
            "Krok 1: Szukanie wszystkich stron bloga...\n",
            "Znaleziono 40 stron\n",
            "  1. https://jaroslawpluciennik.com/blog/\n",
            "  2. https://jaroslawpluciennik.com/blog/page/10/\n",
            "  3. https://jaroslawpluciennik.com/blog/page/11/\n",
            "  4. https://jaroslawpluciennik.com/blog/page/12/\n",
            "  5. https://jaroslawpluciennik.com/blog/page/13/\n",
            "  ... i 35 więcej\n",
            "\n",
            "Krok 2: Pobieranie artykułów z każdej strony...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Przetwarzanie stron: 100%|██████████| 40/40 [00:24<00:00,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RAPORT\n",
            "============================================================\n",
            "Znaleziono artykułów: 397\n",
            "Błędów: 0\n",
            "\n",
            "Zapisano do:\n",
            "  - pluciennik_linki.txt\n",
            "  - pluciennik_linki.json\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#%% import\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import re\n",
        "\n",
        "\n",
        "#%% functions\n",
        "\n",
        "def get_article_links_from_page(page_url):\n",
        "    \"\"\"\n",
        "    Pobiera wszystkie linki do artykułów z danej strony bloga\n",
        "    \"\"\"\n",
        "    article_links = []\n",
        "    try:\n",
        "        r = requests.get(page_url)\n",
        "        r.encoding = 'utf-8'\n",
        "        soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "        # Opcja 1: Szukamy w elementach <article>\n",
        "        for article in soup.find_all('article'):\n",
        "            # Szukamy głównego linku do artykułu\n",
        "            link = article.find('a', href=True)\n",
        "            if link and 'jaroslawpluciennik.com' in link['href']:\n",
        "                href = link['href']\n",
        "                # Wykluczamy linki do kategorii, tagów, archiwów\n",
        "                if not any(x in href for x in ['/category/', '/tag/', '/author/', '/page/']):\n",
        "                    if href not in article_links:\n",
        "                        article_links.append(href)\n",
        "\n",
        "        # Opcja 2: Szukamy w divach z klasą post/entry\n",
        "        if not article_links:\n",
        "            posts = soup.find_all('div', class_=lambda x: x and ('post' in str(x).lower() or 'entry' in str(x).lower()))\n",
        "            for post in posts:\n",
        "                link = post.find('a', href=True)\n",
        "                if link and 'jaroslawpluciennik.com' in link['href']:\n",
        "                    href = link['href']\n",
        "                    if not any(x in href for x in ['/category/', '/tag/', '/author/', '/page/']):\n",
        "                        if href not in article_links:\n",
        "                            article_links.append(href)\n",
        "\n",
        "        # Opcja 3: Szukamy nagłówków z linkami\n",
        "        if not article_links:\n",
        "            for heading in soup.find_all(['h1', 'h2', 'h3', 'h4']):\n",
        "                link = heading.find('a', href=True)\n",
        "                if link and 'jaroslawpluciennik.com' in link['href']:\n",
        "                    href = link['href']\n",
        "                    if not any(x in href for x in ['/category/', '/tag/', '/author/', '/page/']):\n",
        "                        if href not in article_links:\n",
        "                            article_links.append(href)\n",
        "\n",
        "        return article_links\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Błąd pobierania artykułów z {page_url}: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def get_all_pages(blog_url):\n",
        "    \"\"\"\n",
        "    Znajduje wszystkie strony paginacji\n",
        "    \"\"\"\n",
        "    pages = [blog_url]\n",
        "    try:\n",
        "        r = requests.get(blog_url)\n",
        "        r.encoding = 'utf-8'\n",
        "        soup = BeautifulSoup(r.text, 'lxml')\n",
        "\n",
        "        # Opcja 1: Szukamy paginacji\n",
        "        pagination = soup.find('nav', class_=lambda x: x and 'pagination' in str(x).lower())\n",
        "        if not pagination:\n",
        "            pagination = soup.find('div', class_=lambda x: x and 'pagination' in str(x).lower())\n",
        "\n",
        "        if pagination:\n",
        "            for link in pagination.find_all('a', href=True):\n",
        "                page_url = link['href']\n",
        "                # Upewniamy się, że to pełny URL\n",
        "                if not page_url.startswith('http'):\n",
        "                    base_url = blog_url.rstrip('/')\n",
        "                    page_url = base_url + '/' + page_url.lstrip('/')\n",
        "\n",
        "                if page_url not in pages:\n",
        "                    pages.append(page_url)\n",
        "\n",
        "        # Opcja 2: Budujemy strony ręcznie (blog/page/2/, blog/page/3/, etc.)\n",
        "        if len(pages) == 1:\n",
        "            # Sprawdzamy czy istnieje strona 2\n",
        "            test_url = blog_url.rstrip('/') + '/page/2/'\n",
        "            r = requests.get(test_url)\n",
        "            if r.status_code == 200:\n",
        "                page_num = 2\n",
        "                while True:\n",
        "                    next_page = blog_url.rstrip('/') + f'/page/{page_num}/'\n",
        "                    r = requests.get(next_page)\n",
        "                    if r.status_code == 200:\n",
        "                        pages.append(next_page)\n",
        "                        page_num += 1\n",
        "                        time.sleep(0.5)\n",
        "                    else:\n",
        "                        break\n",
        "\n",
        "        return sorted(set(pages))\n",
        "    except Exception as e:\n",
        "        print(f\"Błąd przy szukaniu stron: {e}\")\n",
        "        return pages\n",
        "\n",
        "\n",
        "def get_all_article_links(blog_url):\n",
        "    \"\"\"\n",
        "    Główna funkcja - pobiera wszystkie linki do artykułów\n",
        "    \"\"\"\n",
        "    print(\"Krok 1: Szukanie wszystkich stron bloga...\")\n",
        "    all_pages = get_all_pages(blog_url)\n",
        "\n",
        "    print(f\"Znaleziono {len(all_pages)} stron\")\n",
        "    for i, page in enumerate(all_pages[:5], 1):\n",
        "        print(f\"  {i}. {page}\")\n",
        "    if len(all_pages) > 5:\n",
        "        print(f\"  ... i {len(all_pages) - 5} więcej\")\n",
        "\n",
        "    all_article_links = []\n",
        "    errors = []\n",
        "\n",
        "    print(\"\\nKrok 2: Pobieranie artykułów z każdej strony...\")\n",
        "\n",
        "    for page_url in tqdm(all_pages, desc=\"Przetwarzanie stron\"):\n",
        "        try:\n",
        "            time.sleep(0.5)  # Ostrożność\n",
        "            article_links = get_article_links_from_page(page_url)\n",
        "            all_article_links.extend(article_links)\n",
        "        except Exception as e:\n",
        "            print(f\"\\nBłąd dla {page_url}: {e}\")\n",
        "            errors.append(page_url)\n",
        "\n",
        "    # Usuwamy duplikaty\n",
        "    all_article_links = list(set(all_article_links))\n",
        "\n",
        "    return all_article_links, errors\n",
        "\n",
        "\n",
        "#%% main execution\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    blog_url = \"https://jaroslawpluciennik.com/blog/\"\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"Pobieranie wszystkich linków z jaroslawpluciennik.com/blog/\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Pobierz wszystkie linki\n",
        "    article_links, errors = get_all_article_links(blog_url)\n",
        "\n",
        "    # Sortuj alfabetycznie\n",
        "    article_links.sort()\n",
        "\n",
        "    # Zapisz do pliku tekstowego\n",
        "    with open('pluciennik_linki.txt', 'w', encoding='utf-8') as f:\n",
        "        for link in article_links:\n",
        "            f.write(link + '\\n')\n",
        "\n",
        "    # Zapisz do JSON (z metadanymi)\n",
        "    output_data = {\n",
        "        'source': blog_url,\n",
        "        'total_links': len(article_links),\n",
        "        'links': article_links,\n",
        "        'errors': errors\n",
        "    }\n",
        "\n",
        "    with open('pluciennik_linki.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # Raport\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RAPORT\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Znaleziono artykułów: {len(article_links)}\")\n",
        "    print(f\"Błędów: {len(errors)}\")\n",
        "    if errors:\n",
        "        print(f\"\\nProblematyczne URLe:\")\n",
        "        for error_url in errors:\n",
        "            print(f\"  - {error_url}\")\n",
        "    print(f\"\\nZapisano do:\")\n",
        "    print(f\"  - pluciennik_linki.txt\")\n",
        "    print(f\"  - pluciennik_linki.json\")\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% import\n",
        "from __future__ import unicode_literals\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime\n",
        "from time import mktime\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import json\n",
        "import xlsxwriter\n",
        "\n",
        "\n",
        "#%% functions\n",
        "\n",
        "def date_change_format(date_string):\n",
        "    \"\"\"\n",
        "    Konwertuje datę z różnych formatów na \"YYYY-MM-DD\"\n",
        "    Obsługuje formaty:\n",
        "    - \"09 marzec 2023\"\n",
        "    - \"2023-03-09\"\n",
        "    - \"09.03.2023\"\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Usuwamy dodatkowe białe znaki\n",
        "        date_string = ' '.join(date_string.strip().split())\n",
        "\n",
        "        # Jeśli już jest w formacie YYYY-MM-DD\n",
        "        if re.match(r'\\d{4}-\\d{2}-\\d{2}', date_string):\n",
        "            return date_string[:10]\n",
        "\n",
        "        # Jeśli jest datetime z czasem\n",
        "        if 'T' in date_string:\n",
        "            return date_string.split('T')[0]\n",
        "\n",
        "        # Słownik z obiema formami miesięcy\n",
        "        lookup_table = {\n",
        "            # Dopełniacz\n",
        "            \"stycznia\": \"01\", \"lutego\": \"02\", \"marca\": \"03\", \"kwietnia\": \"04\",\n",
        "            \"maja\": \"05\", \"czerwca\": \"06\", \"lipca\": \"07\", \"sierpnia\": \"08\",\n",
        "            \"września\": \"09\", \"października\": \"10\", \"listopada\": \"11\", \"grudnia\": \"12\",\n",
        "            # Mianownik\n",
        "            \"styczeń\": \"01\", \"luty\": \"02\", \"marzec\": \"03\", \"kwiecień\": \"04\",\n",
        "            \"maj\": \"05\", \"czerwiec\": \"06\", \"lipiec\": \"07\", \"sierpień\": \"08\",\n",
        "            \"wrzesień\": \"09\", \"październik\": \"10\", \"listopad\": \"11\", \"grudzień\": \"12\"\n",
        "        }\n",
        "\n",
        "        # Zamieniamy nazwę miesiąca na numer\n",
        "        for k, v in lookup_table.items():\n",
        "            date_string = date_string.replace(k, v)\n",
        "\n",
        "        # Format DD.MM.YYYY\n",
        "        if re.match(r'\\d{1,2}\\.\\d{1,2}\\.\\d{4}', date_string):\n",
        "            result = time.strptime(date_string, \"%d.%m.%Y\")\n",
        "        # Format DD MM YYYY\n",
        "        else:\n",
        "            result = time.strptime(date_string, \"%d %m %Y\")\n",
        "\n",
        "        changed_date = datetime.fromtimestamp(mktime(result))\n",
        "        new_date = format(changed_date.date())\n",
        "        return new_date\n",
        "    except Exception as e:\n",
        "        print(f\"Błąd konwersji daty '{date_string}': {e}\")\n",
        "        return \"no date\"\n",
        "\n",
        "\n",
        "def dictionary_of_article(article_link):\n",
        "    \"\"\"\n",
        "    Pobiera szczegóły artykułu ze strony jaroslawpluciennik.com\n",
        "    Zwraca dane w tym samym formacie co poprzednie scrapery\n",
        "    \"\"\"\n",
        "    try:\n",
        "        r = requests.get(article_link)\n",
        "        r.encoding = 'utf-8'\n",
        "        html_text = r.text\n",
        "\n",
        "        # Obsługa rate limiting\n",
        "        while '429 Too Many Requests' in html_text:\n",
        "            time.sleep(5)\n",
        "            r = requests.get(article_link)\n",
        "            r.encoding = 'utf-8'\n",
        "            html_text = r.text\n",
        "\n",
        "        soup = BeautifulSoup(html_text, 'lxml')\n",
        "\n",
        "        # Data publikacji\n",
        "        try:\n",
        "            date_element = soup.find('time')\n",
        "            if date_element:\n",
        "                # Próbuj datetime attribute\n",
        "                date_text = date_element.get('datetime') or date_element.get_text(strip=True)\n",
        "                date_of_publication = date_change_format(date_text)\n",
        "            else:\n",
        "                # Alternatywnie szukaj w spanach/divach z \"date\"\n",
        "                date_element = soup.find(['span', 'div'], class_=lambda x: x and 'date' in str(x).lower())\n",
        "                if date_element:\n",
        "                    date_text = date_element.get_text(strip=True)\n",
        "                    date_of_publication = date_change_format(date_text)\n",
        "                else:\n",
        "                    date_of_publication = \"no date\"\n",
        "        except Exception as e:\n",
        "            print(f\"Błąd parsowania daty dla {article_link}: {e}\")\n",
        "            date_of_publication = \"no date\"\n",
        "\n",
        "        # Tytuł\n",
        "        try:\n",
        "            title_element = soup.find('h1')\n",
        "            title = title_element.get_text(strip=True) if title_element else \"no title\"\n",
        "        except:\n",
        "            title = \"no title\"\n",
        "\n",
        "        # Autor\n",
        "        try:\n",
        "            # Opcja 1: rel=\"author\"\n",
        "            author_element = soup.find('a', rel='author')\n",
        "            if not author_element:\n",
        "                # Opcja 2: klasa z \"author\"\n",
        "                author_element = soup.find(['span', 'div', 'a'], class_=lambda x: x and 'author' in str(x).lower())\n",
        "\n",
        "            if author_element:\n",
        "                author = author_element.get_text(strip=True)\n",
        "                # Usuwamy prefix \"Autor:\", \"By:\" itp.\n",
        "                author = re.sub(r'^(Autor|By|Opublikował|Posted by):\\s*', '', author, flags=re.IGNORECASE)\n",
        "            else:\n",
        "                # Domyślnie Jarosław Pluciennik (to jego blog)\n",
        "                author = \"Jarosław Pluciennik\"\n",
        "        except:\n",
        "            author = \"Jarosław Pluciennik\"\n",
        "\n",
        "        # Treść artykułu\n",
        "        try:\n",
        "            # Próbujemy różnych opcji\n",
        "            article_body = soup.find('div', class_=lambda x: x and 'entry-content' in str(x).lower())\n",
        "            if not article_body:\n",
        "                article_body = soup.find('div', class_=lambda x: x and 'post-content' in str(x).lower())\n",
        "            if not article_body:\n",
        "                article_body = soup.find('div', class_=lambda x: x and 'article-content' in str(x).lower())\n",
        "            if not article_body:\n",
        "                article_body = soup.find('article')\n",
        "\n",
        "            if article_body:\n",
        "                text = article_body.get_text(strip=True).replace('\\n', ' ').replace('\\xa0', ' ')\n",
        "            else:\n",
        "                text = \"no text\"\n",
        "        except:\n",
        "            text = \"no text\"\n",
        "\n",
        "        # Kategoria\n",
        "        try:\n",
        "            category_links = soup.find_all('a', rel='category')\n",
        "            if not category_links:\n",
        "                category_links = soup.find_all('a', class_=lambda x: x and 'category' in str(x).lower())\n",
        "\n",
        "            if category_links:\n",
        "                categories = [cat.get_text(strip=True) for cat in category_links]\n",
        "                category = ' | '.join(categories)\n",
        "            else:\n",
        "                category = \"no category\"\n",
        "        except:\n",
        "            category = \"no category\"\n",
        "\n",
        "        # Linki zewnętrzne\n",
        "        try:\n",
        "            if article_body:\n",
        "                links = [a['href'] for a in article_body.find_all('a', href=True)]\n",
        "                # Filtrujemy linki wewnętrzne\n",
        "                external_links = [link for link in links if not re.search(r'jaroslawpluciennik\\.com', link)]\n",
        "                external_links = ' | '.join(external_links) if external_links else None\n",
        "            else:\n",
        "                external_links = None\n",
        "        except (AttributeError, KeyError, IndexError):\n",
        "            external_links = None\n",
        "\n",
        "        # Zdjęcia\n",
        "        try:\n",
        "            images = []\n",
        "\n",
        "            # 1. Thumbnail / post-thumbnail (główne zdjęcie artykułu)\n",
        "            thumbnail_div = soup.find('div', class_=lambda x: x and 'post-thumbnail' in str(x).lower())\n",
        "            if thumbnail_div:\n",
        "                thumb_img = thumbnail_div.find('img', src=True)\n",
        "                if thumb_img:\n",
        "                    images.append(thumb_img['src'])\n",
        "\n",
        "            # 2. Featured image (alternatywna nazwa)\n",
        "            if not images:\n",
        "                featured_img = soup.find('img', class_=lambda x: x and 'featured' in str(x).lower())\n",
        "                if not featured_img:\n",
        "                    featured_div = soup.find('div', class_=lambda x: x and 'featured' in str(x).lower())\n",
        "                    if featured_div:\n",
        "                        featured_img = featured_div.find('img')\n",
        "\n",
        "                if featured_img and featured_img.get('src'):\n",
        "                    if featured_img['src'] not in images:\n",
        "                        images.append(featured_img['src'])\n",
        "\n",
        "            # 3. Zdjęcia w treści artykułu\n",
        "            if article_body:\n",
        "                content_images = [img['src'] for img in article_body.find_all('img', src=True)]\n",
        "                for img_src in content_images:\n",
        "                    if img_src not in images:\n",
        "                        images.append(img_src)\n",
        "\n",
        "            # 4. Inne możliwe miejsca na obrazy (header, figure, etc.)\n",
        "            for container_class in ['entry-header', 'article-header', 'post-header']:\n",
        "                header = soup.find('div', class_=container_class)\n",
        "                if header:\n",
        "                    header_images = [img['src'] for img in header.find_all('img', src=True)]\n",
        "                    for img_src in header_images:\n",
        "                        if img_src not in images:\n",
        "                            images.append(img_src)\n",
        "\n",
        "            has_images = len(images) > 0\n",
        "            photos_links = ' | '.join(images) if images else None\n",
        "        except (AttributeError, KeyError, IndexError):\n",
        "            has_images = False\n",
        "            photos_links = None\n",
        "\n",
        "        # Filmy (iframe)\n",
        "        try:\n",
        "            if article_body:\n",
        "                iframes = [iframe['src'] for iframe in article_body.find_all('iframe', src=True)]\n",
        "                has_videos = len(iframes) > 0\n",
        "            else:\n",
        "                has_videos = False\n",
        "        except:\n",
        "            has_videos = False\n",
        "\n",
        "        dictionary_of_article = {\n",
        "            \"Link\": article_link,\n",
        "            \"Data publikacji\": date_of_publication,\n",
        "            \"Tytuł artykułu\": title.replace('\\xa0', ' '),\n",
        "            \"Tekst artykułu\": text,\n",
        "            \"Autor\": author,\n",
        "            \"Kategoria\": category,\n",
        "            \"Linki zewnętrzne\": external_links,\n",
        "            \"Zdjęcia/Grafika\": has_images,\n",
        "            \"Filmy\": has_videos,\n",
        "            \"Linki do zdjęć\": photos_links\n",
        "        }\n",
        "\n",
        "        all_results.append(dictionary_of_article)\n",
        "\n",
        "    except AttributeError as e:\n",
        "        errors.append(article_link)\n",
        "        print(f\"Błąd dla {article_link}: {e}\")\n",
        "    except Exception as e:\n",
        "        errors.append(article_link)\n",
        "        print(f\"Nieoczekiwany błąd dla {article_link}: {e}\")\n",
        "\n",
        "\n",
        "#%% main execution\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Wczytaj linki z pliku\n",
        "    try:\n",
        "        with open('pluciennik_linki.txt', 'r', encoding='utf-8') as f:\n",
        "            article_links = [line.strip() for line in f if line.strip()]\n",
        "        print(f\"Wczytano {len(article_links)} linków z pliku\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Nie znaleziono pliku pluciennik_linki.txt\")\n",
        "        print(\"Użyj najpierw get_pluciennik_links.py aby pobrać linki!\")\n",
        "        print(\"\\nLub podaj linki ręcznie:\")\n",
        "        article_links = [\n",
        "            # Wstaw tutaj linki do artykułów\n",
        "            # \"https://jaroslawpluciennik.com/blog/artykul1/\",\n",
        "            # \"https://jaroslawpluciennik.com/blog/artykul2/\",\n",
        "        ]\n",
        "\n",
        "    if not article_links:\n",
        "        print(\"Brak linków do przetworzenia!\")\n",
        "        exit(1)\n",
        "\n",
        "    all_results = []\n",
        "    errors = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Rozpoczynam scraping artykułów z jaroslawpluciennik.com\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    # Scraping z progress barem\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        list(tqdm(executor.map(dictionary_of_article, article_links), total=len(article_links)))\n",
        "\n",
        "    # Zapisywanie wyników\n",
        "    timestamp = datetime.today().date()\n",
        "\n",
        "    # JSON\n",
        "    with open(f'pluciennik_{timestamp}.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)\n",
        "\n",
        "    # Excel\n",
        "    df = pd.DataFrame(all_results)\n",
        "    with pd.ExcelWriter(f\"pluciennik_{timestamp}.xlsx\",\n",
        "                       engine='xlsxwriter',\n",
        "                       engine_kwargs={'options': {'strings_to_urls': False}}) as writer:\n",
        "        df.to_excel(writer, 'Posts', index=False)\n",
        "\n",
        "    # Raport\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Scraping zakończony!\")\n",
        "    print(f\"Przetworzono artykułów: {len(all_results)}\")\n",
        "    print(f\"Błędów: {len(errors)}\")\n",
        "    if errors:\n",
        "        print(f\"\\nLinki z błędami (pierwsze 10):\")\n",
        "        for error_link in errors[:10]:\n",
        "            print(f\"  - {error_link}\")\n",
        "        if len(errors) > 10:\n",
        "            print(f\"  ... i {len(errors) - 10} więcej\")\n",
        "    print(f\"\\nPliki wyjściowe:\")\n",
        "    print(f\"  - pluciennik_{timestamp}.json\")\n",
        "    print(f\"  - pluciennik_{timestamp}.xlsx\")\n",
        "    print(f\"{'='*60}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXNu6DyheFmS",
        "outputId": "28ed4649-d0d4-46e2-aaaa-f353d42f1efc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wczytano 397 linków z pliku\n",
            "\n",
            "============================================================\n",
            "Rozpoczynam scraping artykułów z jaroslawpluciennik.com\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 397/397 [01:47<00:00,  3.69it/s]\n",
            "/tmp/ipython-input-455744910.py:299: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
            "  df.to_excel(writer, 'Posts', index=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Scraping zakończony!\n",
            "Przetworzono artykułów: 397\n",
            "Błędów: 0\n",
            "\n",
            "Pliki wyjściowe:\n",
            "  - pluciennik_2026-01-12.json\n",
            "  - pluciennik_2026-01-12.xlsx\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "mb0_UFzMehkj",
        "outputId": "de84b847-9fe3-4701-eede-56ec395dc43c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Link Data publikacji  \\\n",
              "0  https://jaroslawpluciennik.com/2019/07/22/gosc...      2019-07-22   \n",
              "1  https://jaroslawpluciennik.com/2019/08/12/else...      2019-08-12   \n",
              "2  https://jaroslawpluciennik.com/2019/08/14/gwia...      2019-08-14   \n",
              "3  https://jaroslawpluciennik.com/2019/07/25/swie...      2019-07-25   \n",
              "4  https://jaroslawpluciennik.com/2019/08/19/bum-...      2019-08-19   \n",
              "\n",
              "                                      Tytuł artykułu  \\\n",
              "0             Gościu siądź pod mym liściem… tęczowym   \n",
              "1  Elsevier, kalifornijska odwaga i polskie przyg...   \n",
              "2        Gwiazda literaturoznawcza za 200 punktów!!!   \n",
              "3                               Święto Łodzi i orgia   \n",
              "4  BUM! Baza otwartych sylabusów świata. Może now...   \n",
              "\n",
              "                                      Tekst artykułu                Autor  \\\n",
              "0  Lipa nad Wełtawą w Pradze — symbol CzechGościu...  Jarosław Pluciennik   \n",
              "1  Jak podaje „California Academics Quit Elsevier...  Jarosław Pluciennik   \n",
              "2  Przeanalizowałem listę czasopism w wykazie min...      w. Bialikpisze:   \n",
              "3  Witraż z siedziby Akademii Muzycznej w Łodzi p...  Jarosław Pluciennik   \n",
              "4  Open education concept. Getting education onli...  Jarosław Pluciennik   \n",
              "\n",
              "                                           Kategoria  \\\n",
              "0            różnorodność | tolerancja | Uniwersytet   \n",
              "1                                nauka | Uniwersytet   \n",
              "2                                        Uniwersytet   \n",
              "3  doktor honoris causa | pojednanie między narod...   \n",
              "4                                        Uniwersytet   \n",
              "\n",
              "                                    Linki zewnętrzne  Zdjęcia/Grafika  Filmy  \\\n",
              "0   https://www.eua.eu/101-projects/737-invited.html             True  False   \n",
              "1  https://www.timeshighereducation.com/news/cali...             True  False   \n",
              "2                   http://www.antigonishreview.com/             True  False   \n",
              "3     http://creativecommons.org/licenses/by-sa/3.0/             True  False   \n",
              "4  http://„Can Mapping Curricula Shed Light on Te...             True  False   \n",
              "\n",
              "                                      Linki do zdjęć  \n",
              "0  https://jaroslawpluciennik.com/wp-content/uplo...  \n",
              "1  https://jaroslawpluciennik.com/wp-content/uplo...  \n",
              "2  https://jaroslawpluciennik.com/wp-content/uplo...  \n",
              "3  https://jaroslawpluciennik.com/wp-content/uplo...  \n",
              "4  https://jaroslawpluciennik.com/wp-content/uplo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17c690a2-3877-4192-bafb-c48a74721c78\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Link</th>\n",
              "      <th>Data publikacji</th>\n",
              "      <th>Tytuł artykułu</th>\n",
              "      <th>Tekst artykułu</th>\n",
              "      <th>Autor</th>\n",
              "      <th>Kategoria</th>\n",
              "      <th>Linki zewnętrzne</th>\n",
              "      <th>Zdjęcia/Grafika</th>\n",
              "      <th>Filmy</th>\n",
              "      <th>Linki do zdjęć</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://jaroslawpluciennik.com/2019/07/22/gosc...</td>\n",
              "      <td>2019-07-22</td>\n",
              "      <td>Gościu siądź pod mym liściem… tęczowym</td>\n",
              "      <td>Lipa nad Wełtawą w Pradze — symbol CzechGościu...</td>\n",
              "      <td>Jarosław Pluciennik</td>\n",
              "      <td>różnorodność | tolerancja | Uniwersytet</td>\n",
              "      <td>https://www.eua.eu/101-projects/737-invited.html</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>https://jaroslawpluciennik.com/wp-content/uplo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://jaroslawpluciennik.com/2019/08/12/else...</td>\n",
              "      <td>2019-08-12</td>\n",
              "      <td>Elsevier, kalifornijska odwaga i polskie przyg...</td>\n",
              "      <td>Jak podaje „California Academics Quit Elsevier...</td>\n",
              "      <td>Jarosław Pluciennik</td>\n",
              "      <td>nauka | Uniwersytet</td>\n",
              "      <td>https://www.timeshighereducation.com/news/cali...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>https://jaroslawpluciennik.com/wp-content/uplo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://jaroslawpluciennik.com/2019/08/14/gwia...</td>\n",
              "      <td>2019-08-14</td>\n",
              "      <td>Gwiazda literaturoznawcza za 200 punktów!!!</td>\n",
              "      <td>Przeanalizowałem listę czasopism w wykazie min...</td>\n",
              "      <td>w. Bialikpisze:</td>\n",
              "      <td>Uniwersytet</td>\n",
              "      <td>http://www.antigonishreview.com/</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>https://jaroslawpluciennik.com/wp-content/uplo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://jaroslawpluciennik.com/2019/07/25/swie...</td>\n",
              "      <td>2019-07-25</td>\n",
              "      <td>Święto Łodzi i orgia</td>\n",
              "      <td>Witraż z siedziby Akademii Muzycznej w Łodzi p...</td>\n",
              "      <td>Jarosław Pluciennik</td>\n",
              "      <td>doktor honoris causa | pojednanie między narod...</td>\n",
              "      <td>http://creativecommons.org/licenses/by-sa/3.0/</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>https://jaroslawpluciennik.com/wp-content/uplo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://jaroslawpluciennik.com/2019/08/19/bum-...</td>\n",
              "      <td>2019-08-19</td>\n",
              "      <td>BUM! Baza otwartych sylabusów świata. Może now...</td>\n",
              "      <td>Open education concept. Getting education onli...</td>\n",
              "      <td>Jarosław Pluciennik</td>\n",
              "      <td>Uniwersytet</td>\n",
              "      <td>http://„Can Mapping Curricula Shed Light on Te...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>https://jaroslawpluciennik.com/wp-content/uplo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17c690a2-3877-4192-bafb-c48a74721c78')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17c690a2-3877-4192-bafb-c48a74721c78 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17c690a2-3877-4192-bafb-c48a74721c78');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f84935ab-f730-4cd3-899f-1dd4072e1154\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f84935ab-f730-4cd3-899f-1dd4072e1154')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f84935ab-f730-4cd3-899f-1dd4072e1154 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 397,\n  \"fields\": [\n    {\n      \"column\": \"Link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 397,\n        \"samples\": [\n          \"https://jaroslawpluciennik.com/2020/11/07/rozmowa-przeswietlenie-protesty-niech-was-diabli/\",\n          \"https://jaroslawpluciennik.com/2023/04/04/opowiesc-podrecznej-w-kulturze-popularnej/\",\n          \"https://jaroslawpluciennik.com/2022/07/07/slownik-ukrainizmow/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Data publikacji\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 376,\n        \"samples\": [\n          \"2024-01-13\",\n          \"2025-08-23\",\n          \"2023-05-11\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tytu\\u0142 artyku\\u0142u\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 396,\n        \"samples\": [\n          \"Nauka w czasie kryzys\\u00f3w\",\n          \"Hity protest song\\u00f3w\",\n          \"Nowy artyku\\u0142: Kultura, retrotopia, tylda\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tekst artyku\\u0142u\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 392,\n        \"samples\": [\n          \"NAUKA W CZASACH KRYZYS\\u00d3W\\u017byjemy w czasach co najmniej dw\\u00f3ch kryzys\\u00f3w: (post)pandemicznego i klimatycznego. Z perspektywy d\\u0142ugoterminowej nie wiadomo, kt\\u00f3ry jest bardziej dotkliwy, cho\\u0107 nie brakuje opinii, \\u017ce oba s\\u0105 ze sob\\u0105 powi\\u0105zane zjawiskiem globalizacji i panowaniem antropocenu.Nauka ju\\u017c dawno nie jest (cho\\u0107 mo\\u017cna si\\u0119 zastanowi\\u0107, czy kiedykolwiek by\\u0142a) wie\\u017c\\u0105 z ko\\u015bci\\u0105 s\\u0142oniow\\u0105 i musi odpowiada\\u0107 na potrzeby spo\\u0142ecze\\u0144stwa, st\\u0105d konieczno\\u015b\\u0107 rozwi\\u0105zywania problem\\u00f3w otoczenia spo\\u0142eczno-gospodarczego. St\\u0105d tak\\u017ce np. nowe zjawiska: wszystkie publikacje naukowe zwi\\u0105zane z COVID-19 by\\u0142y/s\\u0105 natychmiast bezprecedensowo otwierane. Z drugiej strony, ro\\u015bnie mi\\u0119dzynarodowa kooperacja naukowa w wysi\\u0142kach rozwi\\u0105zania szybko kryzysu epidemiologicznego. To s\\u0105 zjawiska, kt\\u00f3re przy\\u015bpieszaj\\u0105.Jakie dzisiaj mamy g\\u0142\\u00f3wne problemy naukowe?W moim wirtualnym studiu dzisiaj:prof. Maciej Zalewski, profesor nauk biologicznych, dyrektor Europejskiego Regionalnego Centrum Ekohydrologii, Dyrektor Katedry Unesco Ekohydrologii i Ekologii Stosowanej na Wydziale Biologii i Ochrony \\u015arodowiska Uniwersytetu \\u0141\\u00f3dzkiego.prof. Monika Marcinkowska, profesor nauk ekonomicznych, specjalistka finansistka i bankowiec, kandydatka do pe\\u0142nienia funkcji prorektorki ds. nauki w kadencji 2020-2024. Od wielu lat kieruje Katedr\\u0105 Bankowo\\u015bci oraz Instytutu Finans\\u00f3w na Wydziale Ekonomiczno-Socjologicznym. Wieloletnia cz\\u0142onkini Komitetu Ewaluacji Naukowej. Jest cz\\u0142onkiem organu doradczego Europejskiego Urz\\u0119du Nadzoru Bankowego (https://eba.europa.eu/), a tak\\u017ce cz\\u0142onkiem rady najlepszego europejskiego think tanku \\u2013 Bruegel.Dr Andrzej Kompa, bizantynista, staro\\u017cytnik, genealog. Prodziekan Wydzia\\u0142u Filozoficzno-Historycznego U\\u0141 ds. jako\\u015bci kszta\\u0142cenia w kadencji 2016-2020.prof. S\\u0142awomir Cie\\u015blak, profesor nauk prawnych, prorektor ds. kszta\\u0142cenia Uniwersytetu \\u0141\\u00f3dzkiego i specjalista post\\u0119powania cywilnego, kandydat na Rektora Uniwersytetu \\u0141\\u00f3dzkiego w kadencji 2020-2024Szanowni Pa\\u0144stwo, czasu mamy ma\\u0142o, my w tym wirtualnym studiu, ale tak\\u017ce czasu jest ma\\u0142o w skali globu. Co pa\\u0144stwo powiecie naszym widzom, jak nauka mo\\u017ce i powinna odpowiedzie\\u0107 na wspomniane kryzysy?susza to jeden z powa\\u017cnych objaw\\u00f3w kryzysu klimatycznegoUdost\\u0119pnij:Kliknij, aby wys\\u0142a\\u0107 odno\\u015bnik e-mailem do znajomego (Otwiera si\\u0119 w nowym oknie)E-mailKliknij by wydrukowa\\u0107 (Otwiera si\\u0119 w nowym oknie)DrukujKliknij, aby udost\\u0119pni\\u0107 na Facebooku (Otwiera si\\u0119 w nowym oknie)FacebookKliknij, aby udost\\u0119pni\\u0107 na LinkedIn (Otwiera si\\u0119 w nowym oknie)LinkedInKliknij, aby udost\\u0119pni\\u0107 na X (Otwiera si\\u0119 w nowym oknie)XKliknij, aby udost\\u0119pni\\u0107 na WhatsApp (Otwiera si\\u0119 w nowym oknie)WhatsAppLubi\\u0119Wczytywanie\\u2026Powi\\u0105zane\",\n          \"Protest songi maj\\u0105 swoj\\u0105 klasyk\\u0119. Spo\\u015br\\u00f3d klasycznych protest song\\u00f3w studenci mogli wybra\\u0107: \\u015awiatowe: Billie Holiday \\u2013 Strange Fruit (1939) Woody Guthrie \\u2013 This Land Is Your Land (1944) John Lennon \\u2013 Imagine (1971) Gil Scott-Heron \\u2013 The Revolution Will Not Be Televised (1971) The Wailers \\u2013 Get Up, Stand Up (1973) Sex Pistols \\u2014 God Save the Queen (1977) Public Enemy \\u2013 Fight The Power (1989) Kendrick Lamar \\u2013 Alright (2015) Rage Against the Machine \\u2013 \\u201eKilling in the Name\\u201d (1992) U2 \\u2013 \\u201eSunday Bloody Sunday\\u201d (1983) Pink Floyd \\u2013 \\u201eAnother Brick In The Wall, Part II\\u201d (1979) Polskie Jacek Kaczmarski \\u2014 \\u201eMury\\u201d (1978) Czes\\u0142aw Niemen \\u2014 \\u201eDziwny jest ten \\u015bwiat\\u201d (1967) Perfekt \\u2014 \\u201eChcemy by\\u0107 sob\\u0105\\u201d (1981) Republika \\u2014 \\u201eKombinat\\u201d (1982) Brygada Kryzys \\u2014 \\u201eCentrala\\u201d (1982) Lombard \\u2014 \\u201eSzklana pogoda\\u201d (1983) Maanam \\u2014 \\u201eNocny patrol\\u201d (1983) Kazik Staszewski \\u2014 \\u201eTw\\u00f3j b\\u00f3l jest lepszy ni\\u017c m\\u00f3j\\u201d (2020) Peja \\u2014 \\u201eM\\u00f3j rap, moja rzeczywisto\\u015b\\u0107\\u201d (2001) Taco Hemingway \\u2014 \\u201ePolskie Tango\\u201d (2020) Zdecydowani faworyci to: Taco Hemingway \\u2014 \\u201ePolskie Tango\\u201d (2020), Brygada Kryzys \\u2014 \\u201eCentrala\\u201d (1982), Jacek Kaczmarski \\u2014 \\u201eMury\\u201d (1978); Billie Holiday \\u2013 Strange Fruit (1939), Rage Against the Machine \\u2013 \\u201eKilling in the Name\\u201d (1992), John Lennon \\u2013 Imagine (1971). W studiu z prof. Jaros\\u0142awem P\\u0142uciennikiem studenci U\\u0141: Hubert, Emilia, Miko\\u0142aj, Kasia i Maciek. #protestsong #protestsongs #protests #rock #klasykarocka #studenckiwyb\\u00f3rifoch #studenciU\\u0141 #polskietango #tacohemingway #rageagainstthemachine #killinginthename #brygadakryzys #centrala #jacekkaczmarski #mury #billieholiday #strangefruit #johnlennon #imagineUdost\\u0119pnij:Kliknij, aby wys\\u0142a\\u0107 odno\\u015bnik e-mailem do znajomego (Otwiera si\\u0119 w nowym oknie)E-mailKliknij by wydrukowa\\u0107 (Otwiera si\\u0119 w nowym oknie)DrukujKliknij, aby udost\\u0119pni\\u0107 na Facebooku (Otwiera si\\u0119 w nowym oknie)FacebookKliknij, aby udost\\u0119pni\\u0107 na LinkedIn (Otwiera si\\u0119 w nowym oknie)LinkedInKliknij, aby udost\\u0119pni\\u0107 na X (Otwiera si\\u0119 w nowym oknie)XKliknij, aby udost\\u0119pni\\u0107 na WhatsApp (Otwiera si\\u0119 w nowym oknie)WhatsAppLubi\\u0119Wczytywanie\\u2026Powi\\u0105zane\",\n          \"Dwa wydarzenia ostatnich tygodni mog\\u0105 wydawa\\u0107 si\\u0119 zupe\\u0142nie nieprzywiedlne do siebie: wst\\u0105pienie na tron Zjednoczonego Kr\\u00f3lestwa Charlesa III  oraz debiut nowego iPhone\\u2019a 14. Jest jednak pewna inicjatywa sprzed trzech lat, kt\\u00f3ra \\u0142\\u0105czy te dwie r\\u00f3\\u017cne przecie\\u017c sprawy. Ta inicjatywa to Terra Carta. Powsta\\u0142a ona w 2019 roku dzi\\u0119ki ksi\\u0119ciu Walii oraz s\\u0142ynnemu \\u2014 by\\u0142emu ju\\u017c \\u2014 projektantowi Apple Johnowi Ive.Ksi\\u0105\\u017c\\u0119 Walii Charles, obecnie kr\\u00f3l Charles III (fot. lic. Depositphotos)Johny Ive jest chyba historycznie najs\\u0142ynniejszym od czas\\u00f3w Steve\\u2019a Jobsa projektantem Apple\\u2019a, kt\\u00f3ry rozsta\\u0142 si\\u0119 niedawno z producentem Mac\\u00f3w i AppleWatch\\u00f3w, i kt\\u00f3remu ta firma zawdzi\\u0119cza bardzo wiele wspania\\u0142ych produkt\\u00f3w designu (np. iPhone). To w\\u0142a\\u015bnie jego wybra\\u0142 Karol, ksi\\u0105\\u017c\\u0119 Walii, dzisiejszy Charles III, aby zaprojektowa\\u0142 piecz\\u0119\\u0107 nazwan\\u0105 jak\\u017ce po kr\\u00f3lewsku \\u2013 po \\u0142acinie \\u2013   Terra Carta. Ta piecz\\u0119\\u0107 z napisami po angielsku i po \\u0142acinie jest od 2021 znakiem rozpoznawczym projektu nagradzania wielkich przedsi\\u0119wzi\\u0119\\u0107 \\u015bwiatowych, kt\\u00f3re b\\u0119d\\u0105 nie tylko dobre dla biznesu i w\\u0142a\\u015bcicieli praw, ale tak\\u017ce dobre dla \\u2014jak\\u017ce um\\u0119czonej \\u2014 naszej planety. To jest Inicjatywa Zr\\u00f3wnowa\\u017conych Rynk\\u00f3w. (Sustainable Markets Initiative)To s\\u0105 kopie piecz\\u0119ci w r\\u00f3\\u017cnym uj\\u0119ciu zestronyprojektu. Motylek widoczny na piecz\\u0119ci na stronie jest poddany animacjiPrzy okazji tego projektu Ive w wywiadzie dla jednego z pism bran\\u017cowych designu (Wallpaper) wyznaje, \\u017ce s\\u0142owem has\\u0142em designu, kt\\u00f3rego nauczy\\u0142 si\\u0119 od Steve\\u2019a Jobsa jest \\u2014 tak tutaj chodzi o design! \\u2014 s\\u0142owo \\u201etroska\\u201d: po angielsku \\u201ecare\\u201d.Jakkolwiek mo\\u017cna mie\\u0107 krytyczny stosunek do idei monarchicznych i imperialistycznych, to inicjatywa ksi\\u0119cia, a obecnie kr\\u00f3la Karola III zas\\u0142uguje na uwag\\u0119 jako ROYAL SEAL OF APPROVAL, nie produkt\\u00f3w wykonywanych dla dworu, ale dla planety. Dla harmonii natury, ludzi i planety\\u2026 jak brzmi has\\u0142o wyryte na piecz\\u0119ci w dw\\u00f3ch j\\u0119zykach powszechnych ludzko\\u015bci\\u2026Ive jest ju\\u017c uszlachcony i nosi dumnie od dekady order Knight Commander of the Order of the British Empire(KBE), teraz jest tak\\u017ce kr\\u00f3lewskim designerem dla przemys\\u0142u i honorowym cz\\u0142onkiem Kr\\u00f3lewskiej Akademii In\\u017cynierii.Co prawda skala jego ostatniego projektu \\u2014 ta piecz\\u0119\\u0107 Terra Carta \\u2014 nie wydaje si\\u0119 tak wielka jak iPhone, to na pewno zas\\u0142uguje na uwag\\u0119 w naszych uciemi\\u0119\\u017conych pandemi\\u0105, wojnami i katastrof\\u0105 klimatyczn\\u0105 czasach. Terra Carta, jak podkre\\u015blaj\\u0105 ludzie zwi\\u0105zani z projektem, napisana jest j\\u0119zykiem nowoczesnego zarz\\u0105dzania a dotyczy g\\u0142\\u00f3wnie obszar\\u00f3w \\u201ezielonych\\u201d inwestycji takich jak loty elektryczne czy bezemisyjne konstrukcje.Piecz\\u0119\\u0107 Terra Carta jest wytworem laboratorium design\\u2019u the Royal College of Art, kt\\u00f3rego kanclerzem jest teraz Johny Ive.Bardzo mnie interesuje i intryguje ten najnowszy produkt Johny\\u2019ego Ive. Troska dotychczas kojarzy\\u0107 si\\u0119 mog\\u0142a z has\\u0142ami piel\\u0119gniarstwa, czy filozofii mieszcza\\u0144skiej Heideggera (niem. Sorge), ale teraz mo\\u017ce tak\\u017ce skojarzy\\u0107 si\\u0119 z trosk\\u0105 \\u2014 well \\u2014 ostateczn\\u0105 \\u2014 o nasz\\u0105 biedn\\u0105 planet\\u0119\\u2026Udost\\u0119pnij:Kliknij, aby wys\\u0142a\\u0107 odno\\u015bnik e-mailem do znajomego (Otwiera si\\u0119 w nowym oknie)E-mailKliknij by wydrukowa\\u0107 (Otwiera si\\u0119 w nowym oknie)DrukujKliknij, aby udost\\u0119pni\\u0107 na Facebooku (Otwiera si\\u0119 w nowym oknie)FacebookKliknij, aby udost\\u0119pni\\u0107 na LinkedIn (Otwiera si\\u0119 w nowym oknie)LinkedInKliknij, aby udost\\u0119pni\\u0107 na X (Otwiera si\\u0119 w nowym oknie)XKliknij, aby udost\\u0119pni\\u0107 na WhatsApp (Otwiera si\\u0119 w nowym oknie)WhatsAppLubi\\u0119Wczytywanie\\u2026Powi\\u0105zane\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Autor\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"Malgorzata Wladyslawa Martynowskapisze:\",\n          \"Krzysztof Bronowskipisze:\",\n          \"Jaros\\u0142aw Pluciennik\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Kategoria\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 383,\n        \"samples\": [\n          \"edukacja | kultura literacka | literatura | nauki o kulturze i religii | polityka spo\\u0142eczna | szkolnictwo wy\\u017csze | t\\u0142umaczenia | Uniwersytet | Uniwersytet \\u0141\\u00f3dzki\",\n          \"j\\u0119zyk polski | Kultura | Kultura literacka | kultura literacka | literatura | literatura | metafora | nauki o kulturze i religii | poezja | Protestantyzm | Religia | sztuka przek\\u0142adu | translatoryka | t\\u0142umaczenia\",\n          \"edukacja | Historia najnowsza | Holokaust | nauki o kulturze i religii | przesz\\u0142o\\u015b\\u0107 | Religia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Linki zewn\\u0119trzne\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 237,\n        \"samples\": [\n          \"http://www.czasopisma.ltn.lodz.pl/index.php/Zagadnienia-Rodzajow-Literackich/issue/view/335\",\n          \"https://en.wikipedia.org/wiki/We_Shall_Overcome#cite_ref-27 | https://www.youtube.com/watch?v=VHzGBzrA6CY | https://www.youtube.com/watch?v=L8hq9LDt7Bg | https://www.youtube.com/watch?v=M_Ld8JGv56E | https://www.youtube.com/watch?v=RkNsEH1GD7Q | https://www.youtube.com/watch?v=nM39QUiAsoM | https://www.youtube.com/watch?v=LrBATPhL0DI | https://www.youtube.com/watch?v=0FXC9sMUTl4 | https://www.youtube.com/watch?v=jig16VK9M44 | http://www.songlyrics.com/martin-luther-king-jr/-we-shall-overcome-lyrics/ | https://www.youtube.com/watch?v=jdzqDy6oR5E | https://www.youtube.com/watch?v=5FbAVOdA15c | https://www.npr.org/templates/story/story.php?storyId=1031839&t=1571223621079\",\n          \"https://www.empik.com/odwaga-poetyki-aktywizm-opor-psalmy-pluciennik-jaroslaw,p1237769944,ksiazka-p | https://youtu.be/53H_nZqwQOQ?si=M14CkgXnpxDS-2We | https://lodz.wyborcza.pl/lodz/7,35136,31638411,po-apelu-biskupy-budde-do-trumpa-odwaga-to-nie-jest-kwestia.html\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Zdj\\u0119cia/Grafika\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Filmy\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Linki do zdj\\u0119\\u0107\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 336,\n        \"samples\": [\n          \"https://jaroslawpluciennik.com/wp-content/uploads/2020/07/depositphotos_55285519_s-2019.jpg?w=1000 | https://jaroslawpluciennik.com/wp-content/uploads/2020/07/depositphotos_12182996_s-2019.jpg?w=1000\",\n          \"https://jaroslawpluciennik.com/wp-content/uploads/2021/01/depositphotos_27056325_s-2019.jpg?w=1000 | https://jaroslawpluciennik.com/wp-content/uploads/2021/01/depositphotos_12735158_s-2019.jpg?w=1000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}